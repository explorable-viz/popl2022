\section{Introduction}
\label{sec:introduction}

Techniques for dynamic dependency analysis have been fruitful, with applications ranging from information-flow security~\cite{sabelfeld03} and optimisation~\cite{kildall73} to debugging and program comprehension~\cite{weiser81,delucia96}. There are, however, few methods suitable for fine-grained analysis of richly structured outputs, such as data visualisations and multidimensional arrays. Dataflow analyses \cite{reps95} tend to focus on analysing variables rather than parts of structured values. Where-provenance~\cite{buneman01} and related data provenance techniques are fine-grained, but specific to relational query languages. Taint tracking \cite{newsome05} is also fine-grained, but works forwards from input to output. For many applications, it would be useful to be able to focus on a particular part of a structured output, and have an analysis isolate the input data pertinent only to that substructure.

This is a need that increasingly arises outside of traditional programming. Journalists and data scientists use programs to compute charts and other visual summaries from data, charts which must be interpreted by colleagues, policy makers and lay readers alike. Interpreting a chart correctly means understanding what the components of the visualisation actually \emph{represent}, i.e.~the mapping between data and visual elements. But this is a hard task, requiring time and expertise, even with access to the data and source code used to create the visualisation. In practice it is easy for innocent (but devastating) mistakes such as transposing two columns of data to go unnoticed~\cite{miller06}. Since visualisations are simply cases of programs that transform structured inputs (data tables) to structured outputs (charts and other graphics), general-purpose language-based techiques for fine-grained dependency tracking should be able to help with this, by making it possible to reveal these relationships automatically to an interested user. In this paper we present such techniques, but first we describe the two specific problems we want to address.

\subsection{Linking structured outputs to structured inputs}
\label{sec:introduction:data-linking}
First, interpreting a chart would be much easier if the user was able to explore the relationship between the computed components of a chart and the underlying data interactively, revealing the relevant relationships on a need-to-know basis. For example, selecting a particular bar in a bar chart could highlight the relevant data in a table, perhaps showing only the relevant rows, as illustrated in \figref{introduction:data-linking}. We could certainly do more and say something about the nature of the relationship (summation, in this case), but even just revealing the relevant data puts a reader in a much better position to fact-check or confirm their own understanding of what they are looking at. Indeed, visualisation designers sometimes create ``data-linked'' artefacts like these by hand, such as Nadieh Bremer's award-winning visualisation of population density growth in Asian cities~\cite{bremer15}, at the cost of significant programming effort. Libraries such as Altair \cite{vanderPlas18} alleviate some of this work, but require data transformations  to specified using a limited set of combinators provided (and understood) the library.

\begin{figure}
   \begin{subfigure}[b]{0.99\textwidth}
      \centering
      {\includegraphics[scale=0.55]{fig/example/data-linking-merged.png}}
   \end{subfigure}\\
   \vspace{2mm}
   \begin{subfigure}{0.65\textwidth}
      \small
      \lstinputlisting[language=Fluid]{fluid/bar-chart.fld.mod}
   \end{subfigure}
   \caption{Fine-grained linking of outputs to inputs, focusing on data for USA (left) and China (right).}
   \label{fig:introduction:data-linking}
\end{figure}

What we would like is to do allow a data scientist to author analyses and visualisations using an expressive functional language like the one shown in \figref{introduction:data-linking}, with data linking provided automatically for the computed artefact as baked-in transparency feature. At the core of this is a program analysis problem: we want to be able to focus on a particular chart element, and determine the inputs that contribute to it. This is a matter of selecting a part of a structured output and performing some kind of backwards analysis that identifies the relevant data. As well providing a path to automation, framing data linking as a program analysis problem invites interesting questions that a hand-crafted solution is unlikely to properly address. For example, does the union of two output selections depend on the union of their respective dependencies? Do dependencies ``round-trip'', in that they identify sufficient resources to reconstruct the selected output? Are they minimal? These questions are important to establishing trust and a language-based approach offers a chance to address them.

\subsection{Linking structured outputs to other structured outputs}
\label{sec:introduction:vis-linking}
Second, visualisations often present distinct but related aspects of data in multiple charts. In this situation the user should be able to focus on (select) a visual element in one chart or other structured output and automatically see elements of a different chart which were computed using related inputs. For example in \figref{introduction:vis-linking} below, selecting a bar on the left should automatically highlight all the related visual elements on the right. This is a well-recognised use case called \emph{brushing and linking}~\cite{becker87}, which is supported by geospatial applications like GeoDa~\cite{anselin06} and charting libraries like Plotly, but tends to be baked into specific views, or require programmer effort and therefore anticipation in advance by the chart designer. Moreover these applications and libraries provide no direct way for the reader to see the common data which explains why elements are related.

\begin{figure}
  \begin{subfigure}[b]{0.99\textwidth}
     \centering
     {\includegraphics[scale=0.58]{fig/example/vis-linking.png}}
  \end{subfigure}\\[2mm]
  \begin{subfigure}{0.8\textwidth}
     \small
     \lstinputlisting[language=Fluid]{fluid/line-chart.fld.mod}
  \end{subfigure}
 \caption{Linking visualisations via common data dependencies}
 \label{fig:introduction:vis-linking}
\end{figure}

Again, we would like to enable a more automated (and ubiquitous) version of brushing and linking, without imposing a burden on the programmer. They should be able to express visualisations and other data transformations using standard functional programming features such as those shown in \figref{introduction:vis-linking}, and have brushing and linking be enabled automatically between computed artefacts which depend on common data. At the core of this requirement is a variant of our original program analysis problem: we want to select a part of the output and perform a backwards analysis to identify the required inputs, as before, but then also to perform a forwards analysis to identify dependent parts of the other output. Moreover, we would also like the brushing and linking feature to be able to provide a concise view of the data that explain why two selections are linked. Note that the intuition behind the forwards analysis here is not the same as the one we appealed to when we mentioned round-tripping: then the (hypothetical) question was whether the selected data was \emph{sufficient} to reconstruct the selected output, whereas to identify related items in another view, we must determine those parts for which the selected data is \emph{necessary}. As before, a language-based approach offers the prospect of addressing these sorts of question in a robust way.

\subsection{Contributions}

To make progress towards these challenges, we present a bidirectional dependency analysis which supports fine-grained data dependencies between inputs and outputs, with appropriate round-tripping properties characterised by Galois connections, and moreover which can be adapted (through its de Morgan dual) to compute similar dependencies between two outputs which depend on common inputs. Recent program slicing techniques \cite{perera12a,perera13a,ricciotti17} allow the user to focus on the output by ``erasing'' parts deemed to be irrelevant; the erased parts, called \emph{holes}, are propagated backwards by a backwards analysis which identifies parts of the program and input which are no longer needed. Although these approaches also enjoy useful round-tripping properties characterised by Galois connections, they only allow focusing on \emph{prefixes} of a structured output, rather than arbitrary substructures, a notion which is not amenable to complementation. Our specific contributions are as follows:

\begin{itemize}
   \item[--] a new bidirectional dependency analysis for a core calculus with lists, records and mutual recursion, which operates on selections of arbitrary parts of data values, and a proof that the analysis is a Galois connection (\secref{data-dependencies});
   \item[--] a second bidirectional dependency analysis, the de Morgan dual of the first, which also forms a Galois connection and which can be combined with the first analysis to link outputs to outputs, plus a comparison of the new approach with \emph{Galois slicing}, a program slicing framework with similar round-tripping properties (\secref{toolkit}) but which is unable to support these features;
   \item[--] a richer surface language called \OurLanguage with familiar functional programming features, including piecewise definitions, pattern matching, list notation and list comprehensions, and an extension of our analysis to the desugaring (\secref{surface-language});
   \item[--] an implementation of Fluid in PureScript, a discussion of strengths and weaknesses of the approach, and opportunities for future work (\secref{evaluation}).
\end{itemize}

\noindent The rest of the paper is structured as follows. We introduce a core calculus in \secref{core-language}. In \secref{data-dependencies} we define a bidirectional data dependency analysis and prove that it forms a Galois connection. \secref{toolkit} describes how this analysis and its de Morgan dual are used in our PureScript implementation to support the kind of linking scenarios motivated above, and compares our approach to related work. \secref{surface-language} presents the surface language, and shows it desugars into the core language via another Galois connection. \secref{conclusion} summarises and discusses opportunities for future work.

%In this paper, we present new language-based data provenance techniques for linking structured outputs, such as visualisations, to structured inputs, and to each other, in a fine-grained way. Our specific contributions are as follows:

