\section{Introduction}

Data, curated by journalists, scientists and policy makers into charts and other visual summaries, is how we understand the changing world around us. But even with access to the relevant data source --- perhaps an Excel spreadsheet or CSV file --- a chart can be hard to interpret correctly. Important features of the underlying data may be obscured or exaggerated by the choice of one plot over another~\cite{weissgerber15} or choices of visual parameter~\cite{correll19}; sometimes it is far from clear what data we are even being presented with \cite{fullfact19}. Innocent (but devastating) mistakes such as transposing two columns of data may go unnoticed for several years, even in widely cited papers~\cite{miller06}. Making sense of (and trusting) a visualisation, even for an expert, means understanding what its visual attributes actually \emph{represent}, which in turn involves the following key comprehension challenges:

\begin{enumerate}
  \item Identifying the mapping between data source and visual elements in the visualisation
  \item Understanding how different views of shared data are related
\end{enumerate}

\noindent Even with the data and source code used to create the visualisation to hand, answering questions such as these is difficult, requiring time and expertise. More typically, readers rely on supposition or defer to authority, leaving them open to manipulation (intentional or otherwise). The basic problem is that visualisations are opaque, disconnected from the data and computations used to create them. Instead we need visualisations which allow a reader to explore the relationship to the underlying data through the visualisation itself, revealing the relevant data and computation on a need-to-know basis, as the reader interacts with it. Building this sort of ``data linked'' visualisation by hand is possible, but a significant undertaking, requiring intimate knowledge of the computational relationship between chart and data, and programming effort to expose that information to the reader. Our proposal is to build these capabilities into visualisations automatically, using new dynamic program analysis techniques to track how the visualisation was computed from data, and new visualisation techniques to expose that information to readers in an intelligible way.

\input{fig/example/convolve-viz}

\subsection{Towards a solution: Galois connections for data-linked visualisation}

Data visualisations are computed views of the data they represent, suggesting that it might be possible to adapt techniques from program analysis and data provenance to provide a runtime infrastructure that automatically supports linked selections. Then the data scientist or visualisation designer can concentrate on cleaning, aggregating and presenting the data, leaving the infrastructure to take care of linking visualisations to the underlying data sources and related visualisations to each other.

The fine-grained relationship between visual elements and data intuitively has the flavour of an adjoint. Given a data selection $D$, we might ask whether it contains the data required to reconstruct a given part of the chart. Dually, given a visual selection $V$, we might ask whether it is small enough to be generated by a given data selection. We then might wonder whether there are minimal/maximal solutions to these problems. These considerations points towards \emph{Galois connections} as a way of formalising these relationships.

The problem of linking cognate visualisations would seem to be inherently \emph{bidirectional}: to understand the sense in which the two charts are related, one must consider how dependencies flow ``backward'' from selections in one chart to the underlying data, and then ``forward'' from the selected data to a corresponding selection in the other chart.

\input{fig/example/convolve-lib}
\input{fig/example/convolve-usage}
