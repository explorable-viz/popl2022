\subsection{Forward and backward Galois dependency}
\label{sec:core-language:fwd-bwd}

Now that we have a way of expressing selections on values and program fragments (\secref{data-dependencies}), we want a means of analysing a given computation and specifying how selection information on its input can determine the selections on its output, and vice versa. This will allow us to achieve the crux of our goal as set out in \secref{introduction:motivation} to bidirectionally link structured outputs to structured inputs in order to track data dependencies.

One can think of selections on the input as the resources that are available to the program, and unselected inputs as unavailable resources. The intuition behind \textit{forward dependency analysis} is then to express that an output is only selected if all the resources required to construct it are available, i.e. they are all selected, hence we use the $\meet$ operation to combine selection information.

Conversely we can think of selections on the output as specifications for resources we want in the output, and unselected outputs as resources of uninterest. \textit{Backward dependency analysis} then expresses that an input is only selected if it was a resource required to construct the selected output.

Both forwards and backwards analyses are performed with respect to a provided fixed computation $\explVal{T}{\rho, e \evalR v}$ as previously defined in \figref{core-language:semantics}. Forward analysis can be thought of as ``replaying'' evaluation and propagating annotations on inputs to annotations on outputs; the trace $\textcolor{gray}{T}$ is necessary to guide forward analysis through the original computation because the presence of holes in the program results in loss of information about the program structure. Backward analysis can be thought of ``rewinding'' evaluation and propagating annotations on outputs to annotations on inputs; the necessity for traces $\textcolor{gray}{T}$ are more obvious as we have no other information about the original program structure. Operationally, one would first evaluate a program to obtain its trace $\textcolor{gray}{T}$ and then run a forward or background analysis over $\textcolor{gray}{T}$ with any lattice desired.

\newpage
\subsubsection{Pattern-matching}

It is necessary to first describe how the notion of pattern-matching translates to forward and backward dependency analysis, as this is how annotated input values are consumed to determine whether we have all the resources required to construct an output. This is defined in \figref{match:fwd-bwd}.

The function $\matchFwdF{w} :: \Sel{v, \boldsymbol{\sigma}}{A} \to \tyProd{\Sel{\boldsymbol{\rho}, \boldsymbol{\kappa}}{A}}{\textcal{A}}$ for forward analysis pattern-matching can be understood in two parts.
%First, it expresses that we match a value $v$ against an eliminator $\sigma$, both of which are annotated, to produce an annotated environment $\rho$ and continuation $\kappa$.
First it re-expresses the relation $\explVal{w}{v, \sigma \matchR \rho, \kappa}$ (given previously in \figref{core-language:semantics}) except that $v$, $\sigma$, $\rho$, and $\kappa$ are now annotated. Second, we make use of the input trace $\textcolor{gray}{w}$ which records the eliminator's pattern we originally matched against. This informs us to take the conjunction of all values in $v$ which correspond to $\textcolor{gray}{w}$ -- the resulting selection $\alpha$ determines if we have all the input resources necessary for consumption when pattern-matching.

Matching against a variable eliminator $\elimVar{x}{\kappa}$ always returns the selection $\top$, as a variable eliminator can accept any value. For Boolean eliminators, the output selection $\alpha$ is simply the selection on the Boolean value we match with i.e. $\annot{\exTrue}{\alpha}$ or $\annot{\exFalse}{\alpha}$ -- intuitively, if this value is selected then it constitutes all the resources required for the match. This is also the case for $\annot{\exNil}{\alpha}$.

For the non-empty list, $\annListComp{v_1}{v_2}{\alpha}$, we must first determine whether $v_1$ and $v_2$ are available as resources by performing forward match analysis on $v_1$ and $v_2$ as the head and tail pattern against the cons case eliminator $\sigma'$ in $\elimList{\kappa}{\sigma'}$; this returns selections $\beta$ and $\beta'$. We then take the meet of these with the selection $\alpha$ of the cons constructor to yield $\alpha \meet \beta \meet \beta'$. In other words, the output from matching against a non-empty list is only available if the head, tail, and cons constructor are available to match with. A similar story holds for forward-matching against records, where the output is only available if both the record constructor and all of its components are available.

Now working in the backwards direction, the function $\matchBwdF{w} :: \tyProd{\Sel{\boldsymbol{\rho}, \boldsymbol{\kappa}}{A}}{\textcal{A}} \to \Sel{v, \boldsymbol{\sigma}}{A}$ can also be understood in two parts. First, we use the trace $\textcolor{gray}{w}$ to reconstruct the shape of the eliminator $\sigma$. The environment $\rho$ and continuation $\kappa$ resulting from the forward pattern-match are then used to determine the original continuation for the branch corresponding to $\textcolor{gray}{w}$; all other branches are considered unused and hence have hole as their continuations. Second, we take the output selection $\alpha$ which tells us if all input resources were available when forward matching, and use this to annotate the original input value $v$.

The rule for variables, $\textcolor{gray}{x}$, discards its output selection $\alpha$ as no selections were originally consumed when forward pattern-matching against a variable eliminator. For traces $\textcolor{gray}{w}$ representing either $\textcolor{gray}{\exTrue}$ or $\textcolor{gray}{\exFalse}$, we take the output selection $\alpha$ and use this to annotate the Boolean value corresponding to $\textcolor{gray}{w}$. The same logic applies to $\textcolor{gray}{\matchNil}$. For non-empty lists, $\textcolor{gray}{\matchCons{w_1}{w_2}}$, we backward match in reverse order against the tail pattern $w_2$ then the head pattern $w_1$ to acquire annotated values $v_2$ and $v_1$. Using this, we reconstruct the value $\annCons{v_1}{v_2}{\alpha}$ where the cons constructor is annotated by the output selection $\alpha$. Similarly for records, $\textcolor{gray}{\matchRec{\vec{\bind{x}{w}}} \concat \bind{y}{w'}}$, we recursively backward match against all of the components of record and annotate the record constructor with the output selection $\alpha$.
% what pattern matching is doing is taking the conjunction of all selections on the values in v that correspond to the trace w

% The intuition behind mapping selections on the input to selections on the output is as a resource consumption, and evaluation consumes values and produces values, and the two kinds of consumptions (ways you can consume values) are primitive operations and pattern matching. Whenever we try to construct an output, we need to check that the resources are available. As primitive operations induce demand on their arguments in that in order to produce an output, this means checking that the selection on the required arguments are there. Structured values like lists are consumed by pattern-matching - whether we are able to construct an output depends on whether any data that was consumed in that local context was available.

% Every function operates as a context that consumes some input through its eliminator and all the selections on the consumed input determine whether any values constructed in that context can be constructed.

\input{fig/core-language/slicing/match}

\subsubsection{Evaluation}

The idea of forward dependency analysis is to propagate selections on the input resources in order to determine the selections on the output value. The function $\evalFwdF{T} :: \tyProd{\Sel{\boldsymbol{\rho},\, e}{A}}{\textcal{A}} \to \Sel{v}{A}$ describes how we take a selected term $e$ and environment $\rho$, along with the selection $\alpha$ of the current context, and consume them to construct the selection information of the output value $v$. When working in the forwards direction, we want to express that a value is only selected if all the terms involved in its construction are selected, hence we use the meet operation to combine selection states.

Evaluating a variable $x$ is equivalent to looking it up in the environment $\rho$, where $\envLookupFwdF{}$ is defined in \figref{core-language:slicing:eval-aux}. Anonymous functions $\exLambda{\sigma}$ simply evaluate to closures, which are unannotated. We begin to see how the $\meet$ operation is used when evaluating an integer $n_{\alpha'}$ with $\alpha$ as the current selection context - this returns $\annot{n}{\alpha \meet \alpha'}$, expressing that the value $n$ is selected if both the term $n$ and the term containing $n$ were selected. The same logic applies to empty lists $\annot{\exNil}{\alpha'}$.

The recursive behaviour of forward analysis is first seen in the rule for records, $\exRec{\vec{\bind{x}{e}}}_{\alpha}$. We begin by forward analysing each term $e_i$ in the record to a selected value $v_i$, and then construct a record $\annot{\vec{\bind{x}{v}}}{\alpha \meet \alpha'}$, which is only selected if the record itself was selected along with the current context $\alpha'$.

For the cons rule, $\exPair{(\rho,\annCons{e_1}{e_2}{\alpha'})}{\alpha}$, we forward analyse $e_1$ and $e_2$ to get annotated values $v_1$ and $v_2$, and then construct the value $\annCons{v_1}{v_2}{\alpha \meet \alpha'}$ where the cons constructor is only selected if both $\exCons{e_1}{e_2}$ and the outer term containing it are selected.

% Give the intuition that what we do with annotation propagation is specifying how we consume resources in the input in order to construct things in the output.

\paragraph{Primitive operations}

Each primitive operation $\phi: \tyInt^{i} \to \tyInt$ must for every $\vec{n}$ with $\length{\vec{n}} = i$ provide a Galois connection $(\primFwdBool{\phi}{\vec{n}}, \primBwdBool{\phi}{\vec{n}})$ between $\Bool^i$ and $\Bool$, which we lift to a Galois connection $(\primFwd{\phi}{\vec{n}}, \primBwd{\phi}{\vec{n}})$ between $\Below{\vec{n}}$ and $\Below{\phi(\vec{n})}$ by defining
\begin{definition}
\label{def:core-language:primop-gc}
\begin{salign}
   \primFwd{\phi}{\vec{n}}(\vec{\annInt{n}{\alpha}}) &= \annInt{m}{\beta}
   \text{ where }
   \primFwdBool{\phi}{\vec{n}}(\vec{\alpha}) = \beta
   \\
   \primBwd{\phi}{\vec{n}}(\annInt{m}{\beta}) &= \vec{\annInt{n}{\alpha}}
   \text{ where }
   \primBwdBool{\phi}{\vec{n}}(\beta) = \vec{\alpha}
\end{salign}
\end{definition}

\noindent where $\vec{\annInt{n}{\alpha}}$ denotes the zip of same-length sequences $\vec{n}$ and $\vec{\alpha}$ with the constructor for integer values. For any $\vec{n}$ with $\length{\vec{n}} \numlt i$, any such $\phi$ also gives rise to an isomorphism between $\Below{\vec{n}}$ and the lattice of partial applications $\Below{\exPrimOp{\phi}{\vec{n}}}$.

\input{fig/core-language/slicing/eval}
\input{fig/core-language/slicing/eval-aux}

\begin{definition}[Hole environment]
Define $\hole_{\vec{\bind{x}{v}}} = \vec{\bind{x}{\hole}}$
\end{definition}

\begin{lemma}[Least environment for $\rho$]
\label{lem:core-language:hole-env}If $\vdash \rho: \Gamma$ then $\hole_{\rho} \leq \rho$.
\end{lemma}

\begin{definition}[Forward and backward functions for environment lookup]
   Suppose $\envLookup{\rho}{x}{v}$. Then define $\envLookupFwdF{\rho,x}: \Below{\rho} \to \Below{v}$ and $\envLookupBwdF{\rho,x}: \Below{v} \to \Below{\rho}$ to be $\bind{x}{-}\envLookupR$ and $\envLookupBwdR{\rho}\bind{x}{-}$ restricted to $\Below{\rho}$ and $\Below{v}$ respectively.
\end{definition}

\begin{lemma}[Galois connection for environment]
\label{lem:core-language:env-get-put}Suppose $\envLookup{\rho}{x}{v}$.
\begin{enumerate}
   \item \label{lem:core-language:env-get-put:1} $\envLookupFwdF{\rho,x}(\envLookupBwdF{\rho,x}(v)) \geq v$.
   \item \label{lem:core-language:env-get-put:2} $\envLookupBwdF{\rho,x}(\envLookupFwdF{\rho,x}(\rho')) \leq \rho'$.
\end{enumerate}
\end{lemma}

\begin{definition}
   \label{def:core-language:closeDefs-bwd}
   Define the relation $\closeDefsBwdR$ as given in \figref{core-language:slicing:eval-aux}.
\end{definition}

\begin{definition}[Forward and backward functions for recursive bindings]
   Suppose $\rho, h \closeDefsR \rho'$. Define $\closeDefsFwdF{\rho,h}: \Below{(\rho, h)} \to \Below{\rho'}$ and $\closeDefsBwdF{\rho,h}: \Below{\rho'} \to \Below{(\rho, h)}$ to be $\closeDefsR$ and $\closeDefsBwdR$ restricted to $\Below{(\rho, h)}$ and $\Below{\rho'}$ respectively.
\end{definition}

\begin{theorem}[Galois connection for recursive bindings]
\label{thm:core-language:closeDefs:gc}
   Suppose $\rho, h \closeDefsR \rho'$.  Then $\closeDefsFwdF{\rho,h} \adjoint \closeDefsBwdF{\rho,h}$.
\end{theorem}

\begin{definition}[Forward and backward functions for evaluation]
   Suppose $T: \rho, e \evalR v$. Define $\evalFwdF{T}: \Below{(\rho, e, \TT)} \to \Below{v}$ and $\evalBwdF{T}: \Below{v} \to \Below{(\rho, e, \TT)}$ to be $\evalFwdR{T}$ and $\evalBwdR{T}$ restricted to $\Below{(\rho, e, \TT)}$ and $\Below{v}$ respectively.
\end{definition}

\begin{theorem}[Galois connection for evaluation]
\label{thm:core-language:eval:gc}
   Suppose $T: \rho, e \evalFwdS v$.  Then $\evalFwdF{T} \adjoint \evalBwdF{T}$.
\end{theorem}

\begin{lemma}[Determinism of pattern-matching]
   Suppose $v, \sigma \matchFwdR{w} \rho, \kappa$ and $v', \sigma' \matchFwdR{w} \rho', \kappa'$. If $(v, \sigma) \eq (v', \sigma)$ then $(\rho, \kappa) \eq (\rho', \kappa')$.
\end{lemma}

\begin{definition}[Forward and backward functions for pattern-matching]
   Suppose $w: v, \sigma \matchR \rho, \kappa$. Define $\matchFwdF{w}: \Below{(v,\sigma,\TT)} \to \Below{(\rho,\kappa)}$ and $\matchBwdF{w}: \Below{(\rho,\kappa)} \to \Below{(v,\sigma,\TT)}$ to be $\matchFwdR{w}$ and $\matchBwdR{w}$ domain-restricted to $\Below{(v,\sigma,\TT)}$ and $\Below{(\rho,\kappa)}$ respectively.
\end{definition}

\begin{theorem}[Galois connection for pattern-matching]
\label{thm:core-language:match:gc}
   Suppose $w: v, \sigma \matchFwdS \rho, \kappa$.  Then $\matchFwdF{w} \adjoint \matchBwdF{w}$.
\end{theorem}
