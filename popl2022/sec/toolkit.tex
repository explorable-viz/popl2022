\section{Galois connections for brushing and linking}
\label{sec:toolkit}

The second problem we set out in \secref{introduction} was the idea of linking selections between outputs computed from the same data. (We call two such outputs \emph{cognate}.) This so-called ``brushing and linking'' problem~\cite{becker87} has been extensive studied as an interaction paradigm in data visualisation, with the emphasis on visualisation techniques and its value as a comprehension tool, rather than on infrastructure for automation. We noted earlier that, intuitively, brushing and linking has a bidirectional flavour: one must consider how dependencies flow backward from a selection in one output to a selection $v$ in the common data, and then forward from the selected data $v$ to a corresponding selection in the other output. A natural question then is whether the bidirectional analysis established in \secref{data-dependencies} can supply the information required to support an automated solution.

An immediate problem is that the flavour of the forward dependency required here differs from that provided by the forward analysis $\evalFwdF{T}$ defined in \secref{data-dependencies}. That was able to answer the question: what can we compute given only the resources in $v$? But to determine the related data in another output, we must consider not what the data selection $v$ is \emph{sufficient} for, but what it is \emph{necessary} for: those parts of the other output that depend on $v$. Thus the forward dependency operation cannot simply be the upper adjoint $\evalFwdF{T}$, but need an answer to a different question: what would we \emph{not} be able to compute if we lacked the resources in $v$?

We can unpack the problem a bit as follows. Suppose $\Ann{V}_1$ and $\Ann{V}_2$ are the lattices of selections for two views computed from shared data, and $\Ann{D}$ is the lattice of selections for the common data. By analysing how the views are computed from the data, we can obtain two Galois dependency analyses $f: \Ann{V}_1 \to \Ann{D}$ and $g: \Ann{V}_2 \to \Ann{D}$ as shown in \figref{toolkit:de-morgan:non-composable} below:

\input{fig/example/de-morgan.tex}

\noindent Unfortunately, $f$ and $g$ are not composable, as their types makes clear. While the upper adjoint $\upperAdj{g}: \Ann{D} \to \Ann{V}_2$ has the right type to compose with the lower adjoint $\lowerAdj{f}: \Ann{V}_1 \to \Ann{D}$, this is not how Galois connections compose. We now show how the idea of the \emph{complement} of a selection can be used to invert $g$ so that it is composable with $f$, yielding a Galois connection linking $\Ann{V}_1$ to $\Ann{V}_2$ via $\Ann{D}$ (\secref{toolkit:de-morgan-duality}). We also contrast the approach presented in this paper with prior work on program slicing based on Galois connections (\secref{toolkit:galois-slicing}).

\subsection{De Morgan duality}
\label{sec:toolkit:de-morgan-duality}

The analysis in \secref{data-dependencies} relies on the fact that if $\Ann{A}$ is a lattice, then the set $\Sel{\raw{v}}{A}$ of selections of $\raw{v}$ is also a lattice, with the lattice operations defined pointwise. Here we extend that observation to Boolean lattices (or Boolean algebras) $\Ann{A}= \BoolLattice{\Ann{A}}{\top}{\bot}{\meet}{\join}{\neg}$, which are lattices equipped with an involution $\neg$ called \emph{complement} satisfying complementation laws $x \meet \neg x = \bot$ and $x \join \neg x = \top$ and De Morgan equalities $\neg x \meet \neg y = \neg(x \join y)$ and $\neg x \join \neg y = \neg(x \meet y)$. If $\Ann{A}$ is a Boolean algebra, then $\Sel{\raw{v}}{A}$ is also a Boolean algebra, with the Boolean operations, and in particular $\neg_{\raw{v}}: \Sel{\raw{v}}{A} \to \Sel{\raw{v}}{A}$, defined pointwise.

\input{fig/example/convolve-viz}

It is an easy consequence of the complementation and De Morgan laws that any meet-preserving operation $\upperAdj{f}: \Ann{A} \to \Ann{B}$ on Boolean algebras has a join-preserving De Morgan dual $\dual{\upperAdj{f}}: \Ann{A} \to \Ann{B}$ given by $\neg_{\Ann{B}} \after \upperAdj{f} \after \neg_{\Ann{A}}$, whose upper adjoint is $\dual{\lowerAdj{f}}$, the De Morgan dual of $\lowerAdj{f}$. Thus Galois connections on Boolean algebras are closed under De Morgan duality defined component-wise.

\begin{definition}[De Morgan dual of a Galois connection]
   Suppose $\Ann{A}$ and $\Ann{B}$ are Boolean algebras and $f: \Ann{A} \to \Ann{B}$ is a Galois connection $(\lowerAdj{f},\upperAdj{f})$. Define the \emph{De Morgan dual} of $f$ to be the Galois connection $(\dual{\upperAdj{f}}, \dual{\lowerAdj{f}}): \Ann{B} \to \Ann{A}$.
\end{definition}

\noindent De Morgan duality is contravariant, because it swaps the roles of the upper and lower adjoints. So while $f: \Ann{A} \to \Ann{B}$ and $g: \Ann{C} \to \Ann{B}$ are not composable, we can compose $\dual{g}$ with $f$, giving $\dual{g} \after f: \Ann{A} \to \Ann{C}$, as illustrated in \figref{toolkit:de-morgan:composable} above.

\subsubsection{Example: matrix convolution}

\figref{example:convolve-viz} shows $\dual{\evalGC{T}}$, contrasting it with $\evalGC{T}$ and showing how it is able to determine the parts of an output that depend on (necessary for) an input selection. The example computes the convolution of a matrix with a kernel; the computation has an intuitive dependency structure and a naturally visual presentation which makes it useful for conveying the flavour of the two Galois connections. The source code for the example is given in \figref{example:convolve}; our PureScript implementation was used to generate the figures.

\figref{example:convolve-viz:galois-dependency} illustrates the baseline $\evalGC{T}$ Galois connection defined in \secref{data-dependencies}, showing just one of the two possible round-trips. First, the user selects the output cell at position $(2,2)$ (counting rows downwards from $1$). This induces a demand (via the lower adjoint $\evalBwdF{T}$) on the inputs matrix \kw{image} and the kernel \kw{filter}, revealing that the entire kernel was needed to compute the value $1$, but that the elements at $(1,3)$ and $(3,1)$ in the input matrix were not needed, because of zeros present in the kernel. If we then use that input selection to  compute an availability on the output using the upper adjoint $\evalFwdF{T}$, we see that the selection grows: it turns out that the resources needed to make the contents of $(2,2)$ are sufficient to make the contents of $(1,1)$ as well. These larger selections that arise from round-tripping are \emph{closed elements} (fixed points).

\figref{example:convolve-viz:de-morgan-dual} illustrates the De Morgan dual $\dual{\evalGC{T}}$, again showing just one of the two possible round-trips. Here the user selects a cell in the kernel to see the output cells that depend on it. This is computed by negating the input selection, marking it as unavailable resources. Forward-analysing with $\evalFwdF{T}$ reveals that if all inputs are available except kernel cell $(1, 2)$, we can compute only the top row of the output. (We can compute the top row even with the missing kernel cell because we used the method \kw{zero} for dealing with boundaries; \kw{wrap} would have given a different behaviour.) Negating that top row selection produces the output selection shown in the figure, identifying the output cells which depend on kernel cell ($1, 2)$ because they cannot be computed if that input is unavailable.

If we then use this output selection to compute an input selection, the result is not a \emph{demand} in the sense computed by the lower adjoint $\evalBwdF{T}$. Instead of determining the resources needed for the output selection, it determines the resources that would \emph{not} be needed if those outputs were not needed: in other words, those inputs that are \emph{only} needed for the output selection. Here the input selection grows, revealing that if kernel cell $(1, 2)$ is unavailable, then the entire top row of the kernel may as well be unavailable too, and similarly for the bottom 3 rows of the input. Again these larger selections that result from round-tripping (which are fixed points of the round-trip) represent the canonical elements of the dependencies relating the input and output.

\input{fig/example/convolve}

\subsection{Relationship to Galois slicing}
\label{sec:toolkit:galois-slicing}

in the program slicing literature, dynamic analyses based on Galois connections have been developed for pure functional programs~\cite{perera12a}, functional programs with effects~\cite{ricciotti17}, and \piCalculus~\cite{perera16d}. These ``Galois slicing'' techniques have the flavour of what we need, but are unable to compute the kind of sufficiency relation we just outlined. To see the problem, we briefly outline how Galois slicing works. The idea is generalise the notion of program and value to \emph{program slices} and \emph{value slices}, program and values where some subexpressions have been replaced by hole $\hole$. A program slice ``evaluates'' to a \emph{value slice}, a value where some subvalues have been replaced by $\hole$, and dual to this, a value slice induces a (minimal) program slice. One can then extend this basic framework to focus on

The problem with this approach is that it does not readily extend to a notion of selection where the part of the output of interest is not a prefix of the output, but rather a prefix of some subtree. For example, consider the program shown in \figref{example:diff-slicing}, which has the value \lstinline{(0.4, 0.6)}. Because differential slicing includes a program part if is needed \emph{only} by the selected output, in general it underapproximates the parts actually needed for the selected output. In this example, \lstinline{2} and \lstinline{3} are both needed to compute the spine containing the subtree of interest, and so the differential slice does not include them. Differential slicing based on tree prefixes is thus not a suitable technique for computing data dependencies.

\input{fig/example/diff-slicing}

Our approach does have one disadvantage vis-\'a-vis Galois slicing, namely that a program ``selection'' does not really resemble a program, but merely picks out various constants and constructors in the program involved in constructing the output selection. With Galois slicing, the program slice is a program with some holes. Although it is not executable as-is, one could (for example) imagine replacing holes by arbitrary expressions of an appropriate type, in order to recover an executable slice. It is not clear with our approach how to ``extract'' an executable slice for a particular output selection; for primitive values, one could extract the \emph{expression provenance} \cite{acar12}, which would explain how the primitive value was computed using primitive operations, but it is not easy to see how this generalises to structured outputs. Moreover there is no property that ensures the expression provenance is in some sense a projection of the semantics of the original program; \cite{field98} explore this notion of executable slice in the context of term rewriting systems, so perhaps this idea could be adapted to our core calculus and used to derive a notion of execution slice. \todo{Needs work -- perhaps move this paragraph to Related work.}
