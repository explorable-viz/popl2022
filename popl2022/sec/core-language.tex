\newpage

\section{A core language for fine-grained data dependencies}
\label{sec:core-language}

To show how we achieve a system of fine-grained dependency tracking between structured outputs and inputs, we first introduce the core calculus for our language (\secref{core-language:syntax-typing}) and then describe how we can enrich this language with annotations that support the notion of selection (\secref{core-language:selections}). This notion of selection will allow us to link output values to input values and program fragments reponsible for constructing these output values. This core language will serve as the target for which the surface language in \secref{surface-language} desugars into.
\todo{Revisit how well this introduces the structure of the section}

\subsection{Syntax and typing}
\label{sec:core-language:syntax-typing}
\subsubsection{Typing}
We begin by introducing the types $A$ of our language in Figure \ref{fig:core-syntax-type}. These consist of primitive types Booleans $\tyBool$, integers $\tyInt$, and function types $\tyFun{A}{B}$, but additionally lists $\tyList{A}$, vectors $\tyVec{A}$, and records $\tyRec{\vec{\bind{x}{A}}}$ in order to support the kind of fine-grained relationships between input and output typically found in modern programs. The notation $\seq{\bind{x}{A}}$ represents a sequence of bindings of variables $x$ to types $A$.
\input{fig/core-language/syntax-type}


\subsubsection{Terms}
Next we describe the terms of our language as defined in Figure \ref{fig:core-syntax-term}.  These include Boolean constants $\exTrue$ and $\exFalse$, integers $n$, variables $x$, and applications $\exApp{e}{e'}$. We also provide empty lists $\exNil$ and non-empty lists $\exCons{e}{e'}$, vectors $\exVec{e}{x}{e'}$ which are constructed in a comprehension-like notation, and records $\exRec{\vec{\bind{x}{e}}}$ as a sequence of bindings between field names and terms. We include operations for vector lookups $\exVecLookup{e}{e'}$, vector length $\exVecLen{e}$, and record projection $\exRecProj{e}{x}$ for projecting a field $x$ out of the record given by $e$. The final two terms, namely anonymous functions, $\exLambda{\sigma}$, and recursive let-bindings, $\exLetRecMutual{h}{e}$ where $h$ is of the form $\vec{\bind{x}{\sigma}}$, will be explained in \secref{core-language:syntax-eliminator} once we have introduced the idea of an eliminator $\sigma$ which is the only elimination form provided by the core language. Our implementation is untyped but we give typing rules for clarity; the typing rules for terms are given in Figure \ref{fig:core-typing-term} and are straightforward except for those containing eliminators.

\input{fig/core-language/syntax-term}

\noindent

\subsubsection{Eliminators}
\label{sec:core-language:syntax-eliminator}
Eliminators $\sigma$ are defined in Figure \ref{fig:core-syntax-term}. Intuitively, an eliminator specifies how to match against a partial value of some type and selects a continuation $\kappa$ for further execution, where $\kappa$ is either a term $e$ or another eliminator $\sigma$. The variable eliminator $\elimVar{x}{\kappa}$ matches against any value, binds it to $x$, and then continues as $\kappa$. The Boolean eliminator $\elimBool{\kappa}{\kappa'}$ selects either $\kappa$ or $\kappa'$ depending on whether the Boolean value is $\exTrue$ or $\exFalse$. The record eliminator $\elimRec{\seq{x}}{\kappa}$ matches a record with fields $\seq{x}$ and then continues as $\kappa$ with the variables $\seq{x}$ bound to the components of the record. Finally, the list eliminator $\elimList{\kappa}{\sigma}$ maps the empty list to $\kappa$ and a non-empty list to another eliminator $\sigma$ which specifies how the head and tail of the list are to be matched. Eliminators resemble the ``case trees'' commonly used as an intermediate form when compiling languages with pattern-matching \cite{graf20}, and can serve as an elaboration target for more advanced features such as the piecewise definitions described in Section \ref{sec:surface-language}.

The use of nested eliminators to represent demand on sub-values means that, formally, eliminators correspond to Hinze's notion of generalized tries \cite{hinze00} extended with variable bindings. This will become clearer if we consider the typing judgement $\Gamma \vdash \sigma: \tyFun{A}{B}$ for eliminators given in Figure \ref{fig:core-typing-term}. The typing rule for variable eliminators reveals the connection between eliminators and functions: it converts a continuation $\kappa$ which can be assigned type $B$ under the assumption that $x$ is of type $A$ into an eliminator of type $\tyFun{A}{B}$. The typing rule for Boolean eliminators says that to make an eliminator of type $\tyFun{\tyBool}{A}$, we simply need two continuations $\kappa$ and $\kappa'$ of type $A$. The rule for the empty record states that to make an eliminator of type $\tyFun{\tyRec{}}{A}$, we simply need a continuation $\kappa$ of type $A$. The rule for non-empty records allows us to ``uncurry'' an eliminator of type $\tyFun{\tyRec{\vec{\bind{x}{A}}}}{\tyFun{A'}{B}}$ into an eliminator of type $\tyFun{\tyRec{\vec{\bind{x}{A}} \concat \bind{y}{A'}}}{B}$, representing the isomorphism between $\tyFun{\tyFun{A}{B}}{C}$ and $\tyFun{\tyProd{A}{B}}{C}$ but at the level of record types \cite{hinze00}.

The typing rule for list eliminators $\elimList{\kappa}{\sigma}$ combines some of the flavour of record and Boolean eliminators. To make an eliminator of type $\tyFun{\tyList{A}}{B}$, we need a continuation of type $B$ for the empty case, and an eliminator of type $\tyFun{A}{\tyFun{\tyList{A}}{B}}$ which can be treated as an eliminator of type $\tyFun{\tyProd{A}{\tyList{A}}}{B}$ in order to process the head and tail in the non-empty case.

Finally, we can now revisit the term forms $\exLambda{\sigma}$ and $\exLetRecMutual{h}{e}$, having introduced eliminators. If $\sigma$ is an eliminator of type $\tyFun{A}{B}$, then $\exLambda{\sigma}$ is an anonymous function of the same type. If $h$ is of the form $\vec{\bind{x}{\sigma}}$, then $\exLetRecMutual{h}{e}$ introduces a sequence of mutually recursive functions which are in scope in $e$. The typing rule for $\exLetRecMutual{h}{e}$ uses an auxiliary typing judgement $\Gamma \vdash h : \Delta$ which assigns to every $x$ in $\Delta$ a function type $\tyFun{A}{B}$ as long as the $\sigma$ to which $x$ is bound in $h$ has that type.

\input{fig/core-language/typing-term}

\subsubsection{Values}
Lastly, we consider the syntax for values and environments as defined in Figure \ref{fig:core-syntax-value}. An environment $\rho$ is a sequence $\vec{\bind{x}{v}}$ of bindings from variables to values. Values $v, u$ include Booleans $\exTrue$ and $\exFalse$, integers $n$, empty lists $\exNil$ and non-empty lists $\exCons{u}{v}$, records $\exRec{\vec{\bind{x}{v}}}$, and vectors $\exVecVal{\vec{v}}{j}$ of values $\vec{v}$ with length $j$. Additionally, we have partially applied primitives $\exPrimOp{\phi}{\vec{v}}$ where $\phi$ is a primitive operation and $\vec{v}$ is an incomplete sequence of arguments, and function closures $\exClosure{\rho}{h}{\sigma}$ which capture, alongside the definition of a function $\sigma$, an environment $\rho$ and any functions $h$ with which it was mutually defined.
\input{fig/core-language/syntax-value}

\noindent
The typing rules for environments and values are given in Figure \ref{core-typing-value}. The judgement $\vdash \rho: \Gamma$ states that if all the values $v_i$ of the environment are well typed, then the environment itself is well-typed. The typing judgement $\vdash v: A$ is self-explanatory for integers, Booleans, records, lists, and vectors, but we elaborate on partially-applied primitives and closures. The typing rule for primitive operations ensures that only unsaturated applications are first-class values. The typing rule for closures $\exClosure{\rho}{h}{\sigma}$ ensures that all the functions introduced by $h$ are in scope in the definition of the function $\sigma$.
\input{fig/core-language/typing-value}


\subsection{Semantics}

Having introduced our core language in \secref{core-language:syntax-typing}, we now describe their operational semantics (Figure \ref{fig:eval}). This requires introducing a syntax for \textit{traces} (Figure \ref{fig:core-syntax-trace}) which are used to compute analyses that require replaying of computations \cite{perera12a}. Afterwards, in \secref{core-language:selections} we can begin augmenting our language with selections to allow for the tracking of data dependencies. The notions of traces and selections will be used later in \secref{core-language:fwd-bwd} to define forward and backward analyses over a single execution.
\todo{Revisit how well this introduces the structure of the subsection}


\subsubsection{Evaluation}
\label{sec:core-language:eval}


\input{fig/core-language/eval}
\input{fig/core-language/eval-aux}
\input{fig/core-language/syntax-trace}

We explain the semantics for evaluating terms in our language (Figure \ref{fig:eval}) where the judgement $\explVal{T}{\rho, e \evalR v}$ means that a term $e$ under environment $\rho$ evaluates to a value $v$. Traces $\textcolor{gray}{T, U}$ (Figure \ref{fig:core-syntax-trace}) are a notation for the proof terms of the $\evalR$ relation, and are a compact representation for derivation trees in the operational semantics in the sense that they discard unnecessary information from the derivation tree.

The rules for variables $x$, Booleans $\exTrue$ and $\exFalse$, integers $n$, empty lists $\exNil$, and non-empty lists $\exCons{e}{e'}$, are straightforward and have trivial trace forms. The evaluation of records and record projection are also simple, but we begin to note the use of indexed traces which expose additional necessary information about evaluation. For example, evaluating a record $\exRec{\vec{\bind{x}{e}}}$ produces a trace $\textcolor{gray}{T_i}$ for each $\textcolor{gray}{i}$th record component, and record projection $\exRecProj{e}{x_i}$ has a trace $\textcolor{gray}{\trRecProj{T}{\vec{x}}{x_i}}$ where $\textcolor{gray}{\vec{x}}$ records the fields of the record and $\textcolor{gray}{i}$ records the record index projected. The rule for vectors $\exVec{e}{x}{e'}$ evaluates $e'$ to the vector's length $j$ and then evaluates $e$ to $v_i$ for each index $i \numleq j$; the length $j$ is recorded in the trace $\textcolor{gray}{\trVec{\vec{U}}{x}{T}{j}}$. Similarly, the trace $\textcolor{gray}{\trVecLookup{T}{j}{U}{i}}$ for vector lookup $\exVecLookup{e}{e'}$ records the vector length $\textcolor{gray}{j}$ found from evaluating $e$ to $\textcolor{gray}{T_j}$ and the lookup-index $\textcolor{gray}{i}$ from evaluating $e'$ $\textcolor{gray}{U_i}$. The same logic applies to vector length, $\exVecLen{e}$, which extracts and returns the length of a vector.

The rule for recursive let-bindings, $\exLetRecMutual{h}{e}$, makes use of the auxiliary relation $\rho, h \closeDefsR \rho'$ in Figure \ref{fig:core-language:eval-aux}. This produces a new environment $\rho'$ by taking each function definition $\bind{x}{\sigma}$ in $h$ and mapping $x$ to a corresponding closure capturing the old environment $\rho$. It then evaluates $e$ under new environment $\rho'$, leaving as an overall trace $\textcolor{gray}{\trLetRecMutual{h}{T}}$. The final rule for application, $\exApp{e}{e'}$, evaluates $e$ to a closure $\exClosure{\rho_1}{h}{\sigma}$ and $e'$ to a value $v$. It then pattern matches $v$ against the function $\sigma$ to return the correct branch $e''$; this leaves a trace $\textcolor{gray}{w}$ recording which pattern was matched, where the semantics for this relation $\matchR$ is defined later in $\secref{core-language:pattern-match}$. Lastly, it evaluates the function body $e''$ under the concatenation of the intermediate environments produced.

%% it evaluates the function body $e''$ under the closure environment $\rho_1$, the environment of mutually recursive functions in the closure $\rho_1, h \closeDefsR \rho_2$, and the binding of value $v$ against the pattern found in the eliminator $\sigma$.

\todo{Missed out partial primitives, and not sure how to best describe application.}

\subsubsection{Pattern matching}
\label{sec:core-language:pattern-match}
\input{fig/core-language/match}

The judgement $\explVal{w}{v, \sigma \matchR \rho, \kappa}$ for pattern matching, defined in Figure \ref{fig:core-match}, states that matching a value $v$ against an eliminator $\sigma$ evaluates to an environment $\rho$ which binds $v$ to any matched variables in $\sigma$ and a continuation $\kappa$. Traces $\textcolor{gray}{w}$ are proof terms for the $\matchR$ relation and are used to record which pattern was matched against in an eliminator.

For variable eliminators, $\elimVar{x}{\kappa}$ matches any value $v$ against $x$ and outputs an environment binding $x$ to $v$ and the continuation $\kappa$; the trace $\textcolor{gray}{x}$ witnesses that $x$ was matched against. The rules for matching against Boolean eliminators, $\elimBool{\kappa}{\kappa'}$, returns an empty environment, a continuation corresponding to the value of the Boolean matched, and leaves a trace $\textcolor{gray}{\exTrue}$ or $\textcolor{gray}{\exFalse}$ when $\exTrue$ or $\exFalse$ are respectively matched. The unit eliminator $\elimRecEmpty{\kappa}$ always returns its continuation $\kappa$ and an empty environment, with trace $\textcolor{gray}{\texttt{()}}$.

Matching the empty list $\exNil$ against a list eliminator $\elimList{\kappa}{\sigma}$ is trivial and has trace $\textcolor{gray}{\exNil}$. When matching a non-empty list $\exCons{v}{v'}$, we first match against the cons constructor $(\symCons)$ to retrieve the eliminator $\sigma$. We then sequentially match $v$ against the head pattern (with trace $\textcolor{gray}{w}$) and then $v'$ against the tail pattern (with trace $\textcolor{gray}{w'}$) in $\sigma$ to get environments $\rho$ and $\rho'$ which we concatenate, and the final continuation $\kappa'$. The overall trace $\textcolor{gray}{(\exCons{w}{w'})}$ is the cons of traces $\textcolor{gray}{w}$ and $\textcolor{gray}{w'}$.

Finally, we consider the rule for matching a record $\exRec{\vec{\bind{x}{v}} \concat \bind{y}{u}}$ of length $n$ against a record eliminator $\elimRec{\vec{x} \concat y}{\sigma}$. We first recursively match the first $n - 1$ record components, $\vec{\bind{x}{v}}$, against the eliminator $\sigma$ to produce another eliminator $\sigma'$ and a corresponding trace $\textcolor{gray}{\vec{\bind{x}{w}}}$ witnessing these matches. We then match the last record component $\bind{y}{u}$ against $\sigma'$, retrieving the final continuation $\kappa$ and trace $\textcolor{gray}{w'}$. The overall trace $\textcolor{gray}{\exRec{\vec{\bind{x}{w}} \concat \bind{y}{w'}}}$ is the concatenation of traces $\textcolor{gray}{\vec{\bind{x}{w}}}$ and $\textcolor{gray}{\bind{y}{w'}}$. \todo{Needs refining}

% Explain evaluation in a two-stage way like we did with syntax. First we give semantics to pattern matching evaluation and terms without annotation, and then we give forward and backward dependency tracking rules to propagate annotation for annotated terms. We also need to explain the idea of a trace T (a trace is what we refer to as "Match" and "Trace") - these are essentially a compact notation for the proof terms for the evaluation relations which are defined inductively in figure 13 (T :: p, e => v), and operationally are a means of recording the details of program execution. For this we can cite Roly's previous work (imperative functional programs and something else) - these two take a similar approach. Another way to do this would be to define the evaluation relation to additionally output a trace, but here we say that we define evaluation inductively as a relation, so the proof trees of that definition are the traces essentially. What the syntax in figure 11 (matches and traces) does is just define a more compact notation for proof trees for those relations. It's not so much that we compute traces during forward slicing, but that we need traces for forward slicing as well.

%. These are computed during forward slicing, and allows slicing to then proceed backwards afterwards.

\subsection{Representing Selections}
\label{sec:core-language:selections}

Now that the core calculus has been fully specified, this gives us a foundation to begin enriching our language to become suitable for tracking data dependencies. The first thing to establish is the notion of selection which is a way of selecting parts of the program of interest -- this is what will later allow us to perform data dependency analysis in \secref{toolkit}. We use \textit{annotations} to capture the notion of selections by augmenting all first-order data forms to be functors parameterised by an annotation type indicating their selection state.

\input{fig/core-language/syntax-selection}
\input{fig/core-language/slicing/leq-value-elim}
\input{fig/core-language/slicing/leq-term}

\begin{definition}[?]
   Define $\Below{v}$ as the set of all selections on $v$
\end{definition}

\begin{definition}[Hole equivalence]
   Define $\eq$ as the intersection of $\leq$ and $\geq$.
\end{definition}

\input{fig/core-language/slicing/join-value}
\input{fig/core-language/slicing/join-elim}


\noindent
The syntax for annotations $\alpha, \beta$ along with the annotated forms of our core language are given in Figure \ref{fig:core-syntax-selection}. As we are primarily interested in tracking data dependencies between values, we only annotate values and the expression forms which construct values. The annotation-augmented forms for values include: Booleans $\annTrue{\alpha}$ and $\annFalse{\alpha}$, integers $\annInt{n}{\alpha}$, records $\annRec{\vec{\bind{x}{v}}}{\alpha}$, empty lists $\annNil{\alpha}$ and cons nodes $\annCons{u}{v}{\alpha}$, and vectors $\annVecVal{\vec{v}}{\annInt{j}{\alpha}}{\smash{\alpha'}}$. We also introduce holes $\hole$ as a special expression form that expresses annotating every position within a value with the bottom element of a lattice. The corresponding annotated forms for expressions then consist of: holes $\hole$, Booleans $\annTrue{\alpha}$ and $\annFalse{\alpha}$, integers $\annInt{n}{\alpha}$, records $\annRec{\vec{\bind{x}{e}}}{\alpha}$, empty lists $\annNil{\alpha}$ and cons nodes $\annCons{e}{e'}{\alpha}$, and vectors $\annVec{e}{x}{e'}{\alpha}$.

%In order to then propagate the selection-state information of values back to the expressions of our our program which are responsible for creating them, we must also add annotations to the necessary expression forms of our language, $e$.

The selection type is chosen to remain abstract as there are various forms of selection information we may want to express in our language, however we do require them to be a lattice. In other words, selection types must have a top $\top$ and bottom $\bot$ element representing selection and unselection respectively, and a meet $\meet$ and join $\join$ operation where $\top$ and $\bot$ are their left and right units. The most simple choice of lattice would be to set the type of annotations to be the trivial unit lattice -- this lets us recover the original unannotated syntax presented in Figure \ref{fig:core-syntax-term} and \ref{fig:core-syntax-value}. More typically, one would use the Boolean lattice where the top $\top$ and bottom $\bot$ elements are assigned true $\TT$ and false $\FF$, and the meet $\meet$ and $\join$ operations are conjunction $\land$ and disjunction $\lor$. However, we can also use more sophisticated lattices such as a vector of Booleans to represent multiple selections simultaneously.

We state that two terms have the same shape if they are annotations of the same underlying term. The set of annotated terms of a given shape forms a lattice where the top element of the lattice is the annotated term which has top $\top$ as every annotation position, and the bottom element has bottom $\bot$ as every position. The join over two annotation terms of the shape shape is the zip over the structure of the join on the annotations (given in Figures \ref{fig:join-value} and \ref{fig:join-elim}) and the meet operation is defined conversely.

Annotations also induce a partial order on the annotated syntactic forms, where two expressions $e$ and $e'$ are related by $e \leq e'$ if $e$ and $e'$ have the same shape and each annotation in $e$ is below the annotation in the corresponding position in $e'$.  This relation is defined for values and eliminators in Figure \ref{fig:leq-value-eliminator} and terms in Figure \ref{fig:leq-term}.

\subsection{Forward and backward Galois dependency}
\label{sec:core-language:fwd-bwd}

\subsubsection{Pattern-matching}

\input{fig/core-language/slicing/match-fwd}
\input{fig/core-language/slicing/match-bwd}

\begin{lemma}[Determinism of pattern-matching]
   Suppose $v, \sigma \matchFwdR{w} \rho, \kappa$ and $v', \sigma' \matchFwdR{w} \rho', \kappa'$. If $(v, \sigma) \eq (v', \sigma)$ then $(\rho, \kappa) \eq (\rho', \kappa')$.
\end{lemma}

\begin{definition}[Forward and backward functions for pattern-matching]
   Suppose $w: v, \sigma \matchR \rho, \kappa$. Define $\matchFwdF{w}: \Below{(v,\sigma,\TT)} \to \Below{(\rho,\kappa)}$ and $\matchBwdF{w}: \Below{(\rho,\kappa)} \to \Below{(v,\sigma,\TT)}$ to be $\matchFwdR{w}$ and $\matchBwdR{w}$ domain-restricted to $\Below{(v,\sigma,\TT)}$ and $\Below{(\rho,\kappa)}$ respectively.
\end{definition}

\begin{theorem}[Galois connection for pattern-matching]
\label{thm:core-language:match:gc}
   Suppose $w: v, \sigma \matchFwdS \rho, \kappa$.  Then $\matchFwdF{w} \adjoint \matchBwdF{w}$.
\end{theorem}

\subsubsection{Evaluation}

\paragraph{Primitive operations}

Each primitive operation $\phi: \tyInt^{i} \to \tyInt$ must for every $\vec{n}$ with $\length{\vec{n}} = i$ provide a Galois connection $(\primFwdBool{\phi}{\vec{n}}, \primBwdBool{\phi}{\vec{n}})$ between $\Bool^i$ and $\Bool$, which we lift to a Galois connection $(\primFwd{\phi}{\vec{n}}, \primBwd{\phi}{\vec{n}})$ between $\Below{\vec{n}}$ and $\Below{\phi(\vec{n})}$ by defining
\begin{definition}
\label{def:core-language:primop-gc}
\begin{salign}
   \primFwd{\phi}{\vec{n}}(\vec{\annInt{n}{\alpha}}) &= \annInt{m}{\beta}
   \text{ where }
   \primFwdBool{\phi}{\vec{n}}(\vec{\alpha}) = \beta
   \\
   \primBwd{\phi}{\vec{n}}(\annInt{m}{\beta}) &= \vec{\annInt{n}{\alpha}}
   \text{ where }
   \primBwdBool{\phi}{\vec{n}}(\beta) = \vec{\alpha}
\end{salign}
\end{definition}

\noindent where $\vec{\annInt{n}{\alpha}}$ denotes the zip of same-length sequences $\vec{n}$ and $\vec{\alpha}$ with the constructor for integer values. For any $\vec{n}$ with $\length{\vec{n}} \numlt i$, any such $\phi$ also gives rise to an isomorphism between $\Below{\vec{n}}$ and the lattice of partial applications $\Below{\exPrimOp{\phi}{\vec{n}}}$.

\input{fig/core-language/slicing/eval-fwd}
\input{fig/core-language/slicing/eval-bwd}
\input{fig/core-language/slicing/eval-aux}

\begin{definition}[Hole environment]
Define $\hole_{\vec{\bind{x}{v}}} = \vec{\bind{x}{\hole}}$
\end{definition}

\begin{lemma}[Least environment for $\rho$]
\label{lem:core-language:hole-env}If $\vdash \rho: \Gamma$ then $\hole_{\rho} \leq \rho$.
\end{lemma}

\begin{definition}[Forward and backward functions for environment lookup]
   Suppose $\envLookup{\rho}{x}{v}$. Then define $\envLookupFwdF{\rho,x}: \Below{\rho} \to \Below{v}$ and $\envLookupBwdF{\rho,x}: \Below{v} \to \Below{\rho}$ to be $\bind{x}{-}\envLookupR$ and $\envLookupBwdR{\rho}\bind{x}{-}$ restricted to $\Below{\rho}$ and $\Below{v}$ respectively.
\end{definition}

\begin{lemma}[Galois connection for environment]
\label{lem:core-language:env-get-put}Suppose $\envLookup{\rho}{x}{v}$.
\begin{enumerate}
   \item \label{lem:core-language:env-get-put:1} $\envLookupFwdF{\rho,x}(\envLookupBwdF{\rho,x}(v)) \geq v$.
   \item \label{lem:core-language:env-get-put:2} $\envLookupBwdF{\rho,x}(\envLookupFwdF{\rho,x}(\rho')) \leq \rho'$.
\end{enumerate}
\end{lemma}

\begin{definition}
   \label{def:core-language:closeDefs-bwd}
   Define the relation $\closeDefsBwdR$ as given in \figref{core-language:slicing:eval-aux}.
\end{definition}

\begin{definition}[Forward and backward functions for recursive bindings]
   Suppose $\rho, h \closeDefsR \rho'$. Define $\closeDefsFwdF{\rho,h}: \Below{(\rho, h)} \to \Below{\rho'}$ and $\closeDefsBwdF{\rho,h}: \Below{\rho'} \to \Below{(\rho, h)}$ to be $\closeDefsR$ and $\closeDefsBwdR$ restricted to $\Below{(\rho, h)}$ and $\Below{\rho'}$ respectively.
\end{definition}

\begin{theorem}[Galois connection for recursive bindings]
\label{thm:core-language:closeDefs:gc}
   Suppose $\rho, h \closeDefsR \rho'$.  Then $\closeDefsFwdF{\rho,h} \adjoint \closeDefsBwdF{\rho,h}$.
\end{theorem}

\begin{definition}[Forward and backward functions for evaluation]
   Suppose $T: \rho, e \evalR v$. Define $\evalFwdF{T}: \Below{(\rho, e, \TT)} \to \Below{v}$ and $\evalBwdF{T}: \Below{v} \to \Below{(\rho, e, \TT)}$ to be $\evalFwdR{T}$ and $\evalBwdR{T}$ restricted to $\Below{(\rho, e, \TT)}$ and $\Below{v}$ respectively.
\end{definition}

\begin{theorem}[Galois connection for evaluation]
\label{thm:core-language:eval:gc}
   Suppose $T: \rho, e \evalFwdS v$.  Then $\evalFwdF{T} \adjoint \evalBwdF{T}$.
\end{theorem}
