\section{Core calculus}
\label{sec:core-language}

In this section we introduce the core calculus that will be the basis of the bidirectional analyses described in (\secref{data-dependencies}). This notion of selection will allow us to link output values to input values and program fragments reponsible for constructing these output values. This core language will serve as the target for which the surface language in \secref{surface-language} desugars into.
\todo{Revisit how well this introduces the structure of the section}

\subsection{Syntax and typing}
\label{sec:core-language:syntax-typing}

% \subsubsection{Typing}
Although our implementation in untyped, types help describe the structure of the core language.
Figure \ref{fig:core-language:syntax} introduces the types $A, B$ which consist of primitive types $\tyBool$ and $\tyInt$ and function types $\tyFun{A}{B}$, but also lists $\tyList{A}$ and records $\tyRec{\vec{\bind{x}{A}}}$ which exemplify the two primary kinds of structured data we consider: lists represent data with a varying structure, and records represent data with a fixed shape. (Our implementation of the core language also supports matrices, which also have a fixed shape, so with omit these from the formalism.) The notation $\seq{\bind{x}{A}}$ represents a sequence of bindings of variables $x$ to types $A$.

\begin{figure}
   \begin{syntaxfig}
      \input{fig/core-language/syntax-type}
      \input{fig/core-language/syntax-term}
   \end{syntaxfig}
   \caption{Syntax of core language}
   \label{fig:core-language:syntax}
\end{figure}

% \subsubsection{Terms}
The terms of the language are defined in \figref{core-language:syntax}. These include Boolean constants $\exTrue$ and $\exFalse$, integers $n$, variables $x$, and applications $\exApp{e}{e'}$. We also provide empty lists $\exNil$ and non-empty lists $\exCons{e}{e'}$, record construction $\exRec{\vec{\bind{x}{e}}}$ and record projection $\exRecProj{e}{x}$. The final two term forms, anonymous functions $\exLambda{\sigma}$ and recursive let-bindings $\exLetRecMutual{h}{e}$ where $h$ is of the form $\vec{\bind{x}{\sigma}}$, are explained below. First we introduce the elimination form $\sigma$, which we call an \emph{eliminator}. The typing rules for terms are given in Figure \ref{fig:core-typing-term} and are straightforward except for those which refer to eliminators.

\subsubsection{Eliminators}
\label{sec:core-language:syntax-eliminator}
Eliminators $\sigma, \tau$ are also defined in \figref{core-language:syntax}, and are inspired by Hinze's notion of generalised trie \cite{hinze00}. They specify how to match against a partial value of some type and select a continuation $\kappa$ for further execution, where $\kappa$ is either a term $e$ or another eliminator $\sigma$. The Boolean eliminator $\elimBool{\kappa}{\kappa'}$ selects either $\kappa$ or $\kappa'$ depending on whether the boolean value is $\exTrue$ or $\exFalse$. The record eliminator $\elimRec{\seq{x}}{\kappa}$ matches a record with fields $\seq{x}$ and then continues as $\kappa$ with the variables $\seq{x}$ bound to the components of the record. The list eliminator $\elimList{\kappa}{\sigma}$ maps the empty list to $\kappa$ and a non-empty list to another eliminator $\sigma$ which specifies how the head and tail of the list are to be matched. The variable eliminator $\elimVar{x}{\kappa}$ is an extension to Hinze's notion of trie and matches against any value, binds it to $x$, and then continues as $\kappa$. Eliminators resemble the ``case trees'' commonly used as an intermediate form when compiling languages with pattern-matching \cite{graf20}, and can serve as an elaboration target for more advanced features such as the piecewise definitions described in Section \ref{sec:surface-language}.

The use of nested eliminators to represent demand on sub-values will become clearer if we consider the typing judgement $\Gamma \vdash \sigma: \tyFun{A}{B}$ for eliminators given in Figure \ref{fig:core-typing-term}. (Eliminators always have function type, so this should be read as a four-place relation, with $\to$ part of the notation.) The typing rule for variable eliminators reveals the connection between eliminators and functions: it converts a continuation $\kappa$ which can be assigned type $B$ under the assumption that $x$ is of type $A$ into an eliminator of type $\tyFun{A}{B}$. The typing rule for Boolean eliminators says that to make an eliminator of type $\tyFun{\tyBool}{A}$, we simply need two continuations $\kappa$ and $\kappa'$ of type $A$. The rule for the empty record states that to make an eliminator of type $\tyFun{\tyRec{}}{A}$, we simply need a continuation $\kappa$ of type $A$. The rule for non-empty records allows us to ``uncurry'' an eliminator of type $\tyFun{\tyRec{\vec{\bind{x}{A}}}}{\tyFun{A'}{B}}$ into an eliminator of type $\tyFun{\tyRec{\vec{\bind{x}{A}} \concat \bind{y}{A'}}}{B}$, representing the isomorphism between $\tyFun{\tyFun{A}{B}}{C}$ and $\tyFun{\tyProd{A}{B}}{C}$ but at the level of record types \cite{hinze00}.

The typing rule for list eliminators $\elimList{\kappa}{\sigma}$ combines some of the flavour of record and Boolean eliminators. To make an eliminator of type $\tyFun{\tyList{A}}{B}$, we need a continuation of type $B$ for the empty case, and an eliminator of type $\tyFun{A}{\tyFun{\tyList{A}}{B}}$ which can be treated as an eliminator of type $\tyFun{\tyProd{A}{\tyList{A}}}{B}$ in order to process the head and tail in the non-empty case.

Finally, we can now revisit the term forms $\exLambda{\sigma}$ and $\exLetRecMutual{h}{e}$, having introduced eliminators. If $\sigma$ is an eliminator of type $\tyFun{A}{B}$, then $\exLambda{\sigma}$ is an anonymous function of the same type. If $h$ is of the form $\vec{\bind{x}{\sigma}}$, then $\exLetRecMutual{h}{e}$ introduces a sequence of mutually recursive functions which are in scope in $e$. The typing rule for $\exLetRecMutual{h}{e}$ uses an auxiliary typing judgement $\Gamma \vdash h : \Delta$ which assigns to every $x$ in $\Delta$ a function type $\tyFun{A}{B}$ as long as the $\sigma$ to which $x$ is bound in $h$ has that type.

\input{fig/core-language/typing-term}

\subsubsection{Values}
Lastly, we consider the syntax for values and environments as defined in Figure \ref{fig:core-syntax-value}. An environment $\rho$ is a sequence $\vec{\bind{x}{v}}$ of bindings from variables to values. Values $v, u$ include Booleans $\exTrue$ and $\exFalse$, integers $n$, empty lists $\exNil$ and non-empty lists $\exCons{u}{v}$, records $\exRec{\vec{\bind{x}{v}}}$, and vectors $\exVecVal{\vec{v}}{j}$ of values $\vec{v}$ with length $j$. Additionally, we have partially applied primitives $\exPrimOp{\phi}{\vec{v}}$ where $\phi$ is a primitive operation and $\vec{v}$ is an incomplete sequence of arguments, and function closures $\exClosure{\rho}{h}{\sigma}$ which capture, alongside the definition of a function $\sigma$, an environment $\rho$ and any functions $h$ with which it was mutually defined.
\input{fig/core-language/syntax-value}

\noindent
The typing rules for environments and values are given in Figure \ref{core-typing-value}. The judgement $\vdash \rho: \Gamma$ states that if all the values $v_i$ of the environment are well typed, then the environment itself is well-typed. The typing judgement $\vdash v: A$ is self-explanatory for integers, Booleans, records, lists, and vectors, but we elaborate on partially-applied primitives and closures. The typing rule for primitive operations ensures that only unsaturated applications are first-class values. The typing rule for closures $\exClosure{\rho}{h}{\sigma}$ ensures that all the functions introduced by $h$ are in scope in the definition of the function $\sigma$.
\input{fig/core-language/typing-value}

\subsection{Semantics}

Having introduced our core language in \secref{core-language:syntax-typing}, we now describe their operational semantics (Figure \ref{fig:eval}). This requires introducing a syntax for \textit{traces} (Figure \ref{fig:core-syntax-trace}) which are used to compute analyses that require replaying of computations \cite{perera12a}. Afterwards, in \secref{core-language:selections} we can begin augmenting our language with selections to allow for the tracking of data dependencies. The notions of traces and selections will be used later in \secref{core-language:fwd-bwd} to define forward and backward analyses over a single execution.
\todo{Revisit how well this introduces the structure of the subsection}

\subsubsection{Evaluation}
\label{sec:core-language:eval}

\begin{figure}
   \input{fig/core-language/eval}
   \input{fig/core-language/eval-aux}
   \input{fig/core-language/match}
   \caption{Operational semantics}
   \label{fig:core-language:semantics}
\end{figure}

\input{fig/core-language/syntax-trace}

We explain the semantics for evaluating terms in our language (Figure \ref{fig:eval}) where the judgement $\explVal{T}{\rho, e \evalR v}$ means that a term $e$ under environment $\rho$ evaluates to a value $v$. Traces $\textcolor{gray}{T, U}$ (Figure \ref{fig:core-syntax-trace}) are a notation for the proof terms of the $\evalR$ relation, and are a compact representation for derivation trees in the operational semantics in the sense that they discard unnecessary information from the derivation tree.

The rules for variables $x$, Booleans $\exTrue$ and $\exFalse$, integers $n$, empty lists $\exNil$, and non-empty lists $\exCons{e}{e'}$, are straightforward and have trivial trace forms. The evaluation of records and record projection are also simple, but we begin to note the use of indexed traces which expose additional necessary information about evaluation. For example, evaluating a record $\exRec{\vec{\bind{x}{e}}}$ produces a trace $\textcolor{gray}{T_i}$ for each $\textcolor{gray}{i}$th record component, and record projection $\exRecProj{e}{x_i}$ has a trace $\textcolor{gray}{\trRecProj{T}{\vec{x}}{x_i}}$ where $\textcolor{gray}{\vec{x}}$ records the fields of the record and $\textcolor{gray}{i}$ records the record index projected. The rule for vectors $\exVec{e}{x}{e'}$ evaluates $e'$ to the vector's length $j$ and then evaluates $e$ to $v_i$ for each index $i \numleq j$; the length $j$ is recorded in the trace $\textcolor{gray}{\trVec{\vec{U}}{x}{T}{j}}$. Similarly, the trace $\textcolor{gray}{\trVecLookup{T}{j}{U}{i}}$ for vector lookup $\exVecLookup{e}{e'}$ records the vector length $\textcolor{gray}{j}$ found from evaluating $e$ to $\textcolor{gray}{T_j}$ and the lookup-index $\textcolor{gray}{i}$ from evaluating $e'$ $\textcolor{gray}{U_i}$. The same logic applies to vector length, $\exVecLen{e}$, which extracts and returns the length of a vector.

The rule for recursive let-bindings, $\exLetRecMutual{h}{e}$, makes use of the auxiliary relation $\rho, h \closeDefsR \rho'$ in Figure \ref{fig:core-language:eval-aux}. This produces a new environment $\rho'$ by taking each function definition $\bind{x}{\sigma}$ in $h$ and mapping $x$ to a corresponding closure capturing the old environment $\rho$. It then evaluates $e$ under new environment $\rho'$, leaving as an overall trace $\textcolor{gray}{\trLetRecMutual{h}{T}}$. The final rule for application, $\exApp{e}{e'}$, evaluates $e$ to a closure $\exClosure{\rho_1}{h}{\sigma}$ and $e'$ to a value $v$. It then pattern matches $v$ against the function $\sigma$ to return the correct branch $e''$; this leaves a trace $\textcolor{gray}{w}$ recording which pattern was matched, where the semantics for this relation $\matchR$ is defined later in $\secref{core-language:pattern-match}$. Lastly, it evaluates the function body $e''$ under the concatenation of the intermediate environments produced.

%% it evaluates the function body $e''$ under the closure environment $\rho_1$, the environment of mutually recursive functions in the closure $\rho_1, h \closeDefsR \rho_2$, and the binding of value $v$ against the pattern found in the eliminator $\sigma$.

\todo{Missed out partial primitives, and not sure how to best describe application.}

\subsubsection{Pattern matching}
\label{sec:core-language:pattern-match}

The judgement $\explVal{w}{v, \sigma \matchR \rho, \kappa}$ for pattern matching, defined in Figure \ref{fig:core-match}, states that matching a value $v$ against an eliminator $\sigma$ evaluates to an environment $\rho$ which binds $v$ to any matched variables in $\sigma$ and a continuation $\kappa$. Traces $\textcolor{gray}{w}$ are proof terms for the $\matchR$ relation and are used to record which pattern was matched against in an eliminator.

For variable eliminators, $\elimVar{x}{\kappa}$ matches any value $v$ against $x$ and outputs an environment binding $x$ to $v$ and the continuation $\kappa$; the trace $\textcolor{gray}{x}$ witnesses that $x$ was matched against. The rules for matching against Boolean eliminators, $\elimBool{\kappa}{\kappa'}$, returns an empty environment, a continuation corresponding to the value of the Boolean matched, and leaves a trace $\textcolor{gray}{\exTrue}$ or $\textcolor{gray}{\exFalse}$ when $\exTrue$ or $\exFalse$ are respectively matched. The unit eliminator $\elimRecEmpty{\kappa}$ always returns its continuation $\kappa$ and an empty environment, with trace $\textcolor{gray}{\texttt{()}}$.

Matching the empty list $\exNil$ against a list eliminator $\elimList{\kappa}{\sigma}$ is trivial and has trace $\textcolor{gray}{\exNil}$. When matching a non-empty list $\exCons{v}{v'}$, we first match against the cons constructor $(\symCons)$ to retrieve the eliminator $\sigma$. We then sequentially match $v$ against the head pattern (with trace $\textcolor{gray}{w}$) and then $v'$ against the tail pattern (with trace $\textcolor{gray}{w'}$) in $\sigma$ to get environments $\rho$, $\rho'$, and the final continuation $\kappa'$. This leaves us with the concatenation of intermediate environments produced, $\rho \concat \rho'$, continuation $\kappa'$, and overall trace $\textcolor{gray}{(\exCons{w}{w'})}$ combining $\textcolor{gray}{w}$ and $\textcolor{gray}{w'}$ with the cons trace.

Finally, we consider the rule for matching a record $\exRec{\vec{\bind{x}{v}} \concat \bind{y}{u}}$ of length $n$ against a record eliminator $\elimRec{\vec{x} \concat y}{\sigma}$. We first recursively match the first $n - 1$ record components, $\vec{\bind{x}{v}}$, against the eliminator $\sigma$ to produce another eliminator $\sigma'$ and a corresponding trace $\textcolor{gray}{\vec{\bind{x}{w}}}$ witnessing these matches. We then match the last record component $\bind{y}{u}$ against $\sigma'$, retrieving the final continuation $\kappa$ and trace $\textcolor{gray}{w'}$. Similar to non-empty lists, this leaves us with the concatenation of intermediate environments produced, $\rho \concat \rho'$, continuation $\kappa'$, and overall trace $\textcolor{gray}{\exRec{\vec{\bind{x}{w}} \concat \bind{y}{w'}}}$ which concatenates the traces $\textcolor{gray}{\vec{\bind{x}{w}}}$ and $\textcolor{gray}{\bind{y}{w'}}$. \todo{Needs refining}

% Explain evaluation in a two-stage way like we did with syntax. First we give semantics to pattern matching evaluation and terms without annotation, and then we give forward and backward dependency tracking rules to propagate annotation for annotated terms. We also need to explain the idea of a trace T (a trace is what we refer to as "Match" and "Trace") - these are essentially a compact notation for the proof terms for the evaluation relations which are defined inductively in figure 13 (T :: p, e => v), and operationally are a means of recording the details of program execution. For this we can cite Roly's previous work (imperative functional programs and something else) - these two take a similar approach. Another way to do this would be to define the evaluation relation to additionally output a trace, but here we say that we define evaluation inductively as a relation, so the proof trees of that definition are the traces essentially. What the syntax in figure 11 (matches and traces) does is just define a more compact notation for proof trees for those relations. It's not so much that we compute traces during forward slicing, but that we need traces for forward slicing as well.

%. These are computed during forward slicing, and allows slicing to then proceed backwards afterwards.
