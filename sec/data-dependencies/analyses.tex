\subsection{Forward data dependency}
\label{sec:data-dependencies:analyses:fwd}

We now define the core bidirectional data dependency analyses for a fixed computation $T :: \raw{\rho}, \raw{e} \evalR \raw{v}$, where $T$ is a trace. In practice one would obtain $T$ by first evaluating $\raw{e}$ in $\raw{\rho}$, and then run multiple forward or backward analyses over $T$ with appropriate lattices. We start with the forward dependency function $\evalFwdF{T}$ which ``replays'' evaluation, turning input availability into output availability, with $T$ guiding the analysis whenever holes in the input selection would mean the analysis would otherwise get stuck. $\evalFwdF{T}$ uses the auxiliary function $\matchFwdF{w}$ for forward-analysing a pattern-match; we explain this first, as it introduces the key idea of a selection as identifying the data available to a downstream computation.

\subsubsection{Forward match}
\label{sec:data-dependencies:analyses:fwd:pattern-match}

\figref{data-dependencies:match-fwd} defines a family of \emph{forward-match} functions $\matchFwdF{w}$ of type $\Sel{\raw{v}, \raw{\sigma}}{A} \to (\Sel{\raw{\rho}, \raw{\kappa}}{A}) \times \Ann{A}$ for any $w :: \raw{v}, \raw{\sigma} \matchR \raw{\rho}, \raw{\kappa}$. (The definition is presented in a relational style for readability, but should be understood as a total function defined by structural recursion on $w$, which appears in grey to emphasise the connection to \figref{core-language:semantics}.) Forward match replays the match witnessed by $w$, turning availability $(v,\sigma) \in \Sel{\raw{v},\raw{\sigma}}{A}$ on the matched value and eliminator into availability $(\rho,\kappa) \in \Sel{\raw{\rho},{\raw{\kappa}}}{A}$ on the variable bindings and continuation yielded by the match.

$\matchFwdF{w}$ also returns the \emph{meet} of the selection states associated with the part of $\raw{v}$ which was matched by $\raw{\sigma}$. We call this the \emph{argument availability}, since it represents the availability of the matched part of a function argument. In the variable case, the empty part of $\raw{v}$ was matched and so the argument availability in this context is simply $\top$, the unit for $\meet$. In the Boolean case, the argument availability is simply the $\alpha$ on $\annot{\exTrue}{\alpha}$ or $\annot{\exFalse}{\alpha}$; the empty list and empty record cases are similar. In the cons case, we return the meet of the $\alpha$ on the cons node itself with the availabilities $\beta$ and $\beta'$ computed for $v$ and $v'$. Non-empty records are similar, but to process the initial part of the record, we supply the neutral selection state $\top$ on the subrecord in order to use the definition recursively. (Note that these subrecords exist only as intermediate artefacts of the interpreter.)

One might hope to be able to dispense with the match witness $w$ and simply define $\matchFwdS$ by case analysis on $v$ and $\sigma$. However, it is then unclear how to proceed in the event that either $v$ or $\sigma$ is a hole. In particular, it is not clear how to obtain the $\raw{\rho}$ associated with the original pattern-match in order to produce an environment selection $\rho' \in \Sel{\raw{\rho}}{A}$. If $\matchFwdS$ is defined with respect to a known $w$, this can be achieved via additional rules \ruleName{$\matchFwdS$-hole-$v$} and \ruleName{$\matchFwdS$-hole-$\sigma$} that define the behaviour at hole to be the same as the behaviour at any $\eq$-equivalent value in $\Sel{\raw{v}}{A}$ or $\Sel{\raw{\sigma}}{A}$.

Operationally, these hole rules can be interpreted as ``expanding'' the holes in $v$ or $\sigma$, in a shape-preserving way, until another rule of the definition applies. Recall the pattern-matching example from \secref{core-language:pattern-match}. This pattern-match has the witness $\matchCons{\kw{x}}{\kw{xs}}$, recording that the list \kw{\exCons{5}{\exCons{6}{\exNil}}} was matched to the depth of a single cons. Suppose we wish to forward-analyse over the pattern-match using $\hole$ to represent the selection on the matched list. The information in the match witness allows us to expand $\hole$ to $\annCons{\hole}{\hole}{\bot}$ and then use the $\matchFwdS$-cons rule to derive the following forward-match:

\begin{smathpar}
   \inferrule*[left={\ruleName{$\matchFwdS$-hole-$v$}}]
   {
      \inferrule*[left={\ruleName{$\matchFwdS$-cons}}]
      {
         \inferrule*[left={\ruleName{$\matchFwdS$-var}}]
         {
         }
         {
            \matchFwd{\hole}
                     {\elimVar{\kw{x}}{\elimVar{\kw{xs}}{e_2}}}
                     {\kw{x}}
                     {\bind{\kw{x}}{\hole}}
                     {\elimVar{\kw{xs}}{e_2}}
                     {\top}
         }
         \\
         \inferrule*[left={\ruleName{$\matchFwdS$-var}}]
         {
         }
         {
            \matchFwd{\hole}
                     {\elimVar{\kw{xs}}{e_2}}
                     {\kw{xs}}
                     {\bind{\kw{xs}}{\hole}}
                     {e_2}
                     {\top}
         }
      }
      {
         \matchFwd{\annCons{\hole}{\hole}{\bot}}
                  {\elimList{e_1}{\elimVar{\kw{x}}{\elimVar{\kw{xs}}{e_2}}}}
                  {\matchCons{\kw{x}}{\kw{xs}}}
                  {(\bind{\kw{x}}{\hole}) \concat (\bind{\kw{xs}}{\hole})}
                  {e_2}
                  {\bot}
      }
   }
   {
      \matchFwd{\hole}
               {\elimList{e_1}{\elimVar{\kw{x}}{\elimVar{\kw{xs}}{e_2}}}}
               {\matchCons{\kw{x}}{\kw{xs}}}
               {(\bind{\kw{x}}{\hole}) \concat (\bind{\kw{xs}}{\hole})}
               {e_2}
               {\bot}
   }
\end{smathpar}

\vspace{2mm}
\noindent \lemref{match-fwd:monotonic} below implies that an implementation is free to replace any term by a hole-equivalent one of the same shape, with the result of $\matchFwdF{w}$ being unique up to $\eq$. This justifies the strategy of expanding holes just enough for a non-hole rule to apply; there will be exactly one such rule, corresponding to the execution path originally taken, and although there may be multiple possible expansions, they will produce hole-equivalent results. This also explains why it is reasonable to think of $\matchFwdF{w}$ not just as a relation, but as a function.

\begin{lemma}[Monotonicity of $\matchFwdF{w}$]
\label{lem:match-fwd:monotonic}
   Suppose $w :: \raw{v}, \raw{\sigma} \matchR \raw{\rho}, \raw{\kappa}$, with $v, \sigma \matchFwdR{w} \rho, \kappa, \alpha$ and $v', \sigma' \matchFwdR{w} \rho', \kappa', \alpha'$. If $(v, \sigma) \leq (v', \sigma)$ then $(\rho, \kappa, \alpha) \leq (\rho', \kappa', \alpha')$.
\end{lemma}

\input{fig/core-language/slicing/match-fwd}

The forward-match function $\matchFwdF{w}$ is a key component of the forward evaluation function $\evalFwdF{T}$ defined in \secref{data-dependencies:forward-eval} below. When forward-analysing a function call, the argument is forward-matched using $\matchFwdF{w}$, and the resulting argument availability $\alpha$ used to upper-bound the availability of any partial values constructed by that function, establishing a forward link from resources consumed and resources produced. Since the dynamic context of a function call extends over multiple evaluation steps, $\evalFwdF{T}$ is threaded with an additional input $\alpha$ which tracks the active argument availability; at the outermost level, before there are any active function calls, this has the value $\top$.

\subsubsection{Forward evaluation}
\label{sec:data-dependencies:forward-eval}

\figref{data-dependencies:fwd} defines a family of \emph{forward-evaluation} functions $\evalFwdF{T}$ of type $(\Sel{\raw{\rho}, \raw{e}}{A}) \times \Ann{A} \to \Sel{\raw{v}}{A}$ for any $T :: \raw{\rho}, \raw{e} \evalR \raw{v}$. (Like forward match, forward evaluation is presented in a relational style, but should be read as a total function defined by structural recursion on $T$.) Forward evaluation replays $T$, taking a selection $(\rho, e) \in \Sel{\raw{\rho}, \raw{e}}{A}$ identifying the available parts of the environment and program, and an $\alpha \in \Ann{A}$ representing the argument availability for the dynamically innermost function call, and returning a selection $v \in \Sel{\raw{v}}{A}$ identifying the outputs that can be produced using only the available resources. The rules resemble those for the evaluation relation $\evalS$. The general pattern is that each rule takes the active argument availability $\alpha$, combines it (using $\meet$) with any availability supplied on the expression form consumed at that step, and uses the result as the availability of any partial values constructed at that step. The argument availability $\alpha$ is passed down unchanged to any subcomputations, except in the case of function application.

\input{fig/core-language/slicing/eval-fwd}

\Paragraph{Function application} In the application case, the rule must determine a new argument availability for the function body, because the function context is changing. First, we unpacks the $\beta$ stored in the closure, representing the argument availability which was active when the closure was constructed. Then we determine an additional selection state $\beta'$, representing the availability of the matched part of the current argument, by forward-matching $v$ with the eliminator $\sigma$ from the closure. These are combined using $\meet$ to represent the conjoined availability of all arguments that were pattern-matched in order to execute the function body, and the result $\beta \meet \beta'$ used to forward-evaluate the function body. The auxiliary function $\closeDefsFwdF{\rho,h}: (\Sel{\raw{\rho},\raw{h}}{A}) \times \Ann{A} \to \Sel{\raw{\rho}'}{A}$ for any $\smash{\raw{\rho}, \raw{h} \closeDefsR \raw{\rho'}}$ is given at the bottom of \figref{data-dependencies:fwd} and resembles $\closeDefsR$, but captures the active argument availability into each closure.

\Paragraph{Primitive application} Since primitive operations are opaque, their input-output dependencies cannot be derived from their execution, but must be supplied by the primitive operation itself. More specifically, every primitive $\phi \in \tyInt^{i} \to \tyInt$ is required to provide a forward-dependency function $\primFwdBool{\phi}{\vec{n}}: \Ann{A}^i \to \Ann{A}$ for every $\vec{n} \in \tyInt^i$ which specifies how to turn an input selection $\vec{\alpha} \in \Ann{A}^i$ for $\vec{n}$ into an output selection $\alpha'$ on $\exAppPrim{\phi}{\vec{n}}$. There is one such function per possible input $\vec{n}$ so that the dynamic dependencies for that specific call can depend on the values passed to the operation. For example, in our implementation, the dependency function for multiplication establishes (for non-zero $n$) that both $n * 0$ and $0 * n$ depend only on $0$. However, primitives are free to implement forward-dependency however they choose, with the caveat that \secref{data-dependencies:analyses:bwd:eval} will also require $\phi$ to provide a backward-dependency function for any input $\vec{n}$, and \secref{data-dependencies:galois-connections} will require these to be related in a certain way for the consistency of the whole system to be guaranteed.

\Paragraph{Other rules} The remaining rules follow the general pattern. Variable lookup disregards $\alpha$, simply preserving the selection on the value extracted from the environment. The lambda rule captures $\alpha$ in the closure along with the environment; the letrec rule passes $\alpha$ on to $\closeDefsFwdR$ so it can be captured by recursive closures as well. Record projection is more interesting, disregarding not only the argument availability $\alpha$ but also the availability $\beta$ of the record itself. This is because containers are considered to be independent of the values they contain: here, $v_i$ has its own internal availability which is preserved by projection, but there is no implied dependency of the field on the record from which it was projected. Record construction also reflects this principle, preserving the field selections unchanged into the resulting record selection. But since this rule also constructs a partial value --- the record itself --- it must specify an availability on that output. The availability is set to $\alpha \meet \alpha'$, reflecting the dependency of the constructed container on both the constructing expression and the active argument match. The rules for nil, cons, integers and Booleans are similar, since they also construct values.

\Paragraph{Hole cases} Environments have no special $\hole$ form. However, a hole rule is needed to allow forward evaluation to continue in the event that $e$ is $\hole$; this is essential because subsequent steps may result in non-$\hole$ outputs (for example by extracting non-$\hole$ values from $\rho$). The rule is similar to the hole rules for $\matchFwdF{w}$ and again can be understood operationally as using the information in $T$ to expand $\hole$ sufficiently for another rule to apply, with a result which is unique up to $\eq$. In addition, application and record projection must accommodate the case where the selection on the closure or record being eliminated is represented by $\hole$. In these rules $\evalFwdR{T}\eq$ is used to denote the relational composition of $\evalFwdR{T}$ and $\eq$.

\begin{lemma}[Monotonicity of $\evalFwdF{T}$]
   Suppose $T :: \raw{\rho}, \raw{e} \evalR \raw{v}$ with $\rho, e, \alpha \evalFwdR{T} v$ and $\rho', e', \alpha' \evalFwdR{T} v'$. If $(\rho, e, \alpha) \leq (\rho', e', \alpha')$ then $v \leq v'$.
\end{lemma}

\subsection{Backward data dependency}
\label{sec:data-dependencies:analyses:bwd}

The backward dependency function $\evalBwdF{T}$ ``rewinds'' evaluation, turning output demand into input demand, with $T$ guiding the analysis backward. We start with the auxiliary function $\matchBwdF{w}$ which is used for backward-analysing a pattern-match.

\subsubsection{Backward match}
\label{sec:data-dependencies:analyses:bwd:pattern-match}

\figref{data-dependencies:match-bwd} defines a family of \emph{backward-match} functions $\matchBwdF{w}$ of type $(\Sel{\raw{\rho}, \raw{\kappa}}{A}) \times \Ann{A} \to \Sel{\raw{v}, \raw{\sigma}}{A}$ for any $w :: \raw{v}, \raw{\sigma} \matchR \raw{\rho}, \raw{\kappa}$. Backward-match rewinds the match witnessed by $w$, turning demand on the environment and continuation into demand on the value and eliminator that were originally matched. The additional input $\alpha$ represents the downstream demand placed on any resources that were constructed in the context of this match; $\matchBwdF{w}$ transfers this to the matched portion of $\raw{v}$, establishing a backwards link from resources produced to resources consumed in a given function context. We call $\alpha$ the \emph{argument demand} since it represents the demand to be pushed backwards onto the matched part of a function argument.

\input{fig/core-language/slicing/match-bwd}

In the variable case, the empty part of $\raw{v}$ was matched, so $\alpha$ is disregarded. The rule need only ensure that the demand $v$ in the singleton environment $\bind{x}{v}$ is propagated backward. If a Boolean constant was matched, $\alpha$ becomes the demand on that constant, and $\kappa$, capturing the demand on the continuation, is used to construct the demand on the original eliminator, with $\hole$ used to represent the absence of demand on the non-taken branch. (This use of $\hole$ explains why matches $w$ need only retain information about taken branches.) The nil case is similar.

For a cons match $\matchCons{w}{w'}$, we split the environment into $\rho$ and $\rho'$, using the fact that there is a unique well-typed decomposition. We then backward-match $w$ and $w'$ recursively to obtain $v$ and $v'$, representing the demand on the head and tail of the list. These are combined into the demand on the entire list, using $\alpha$ as the demand on the root cons node. The eliminator selection $\sigma$ represents the demand on the interim eliminator used to match the tail, and $\tau$ the demand on the eliminator used to match the head; these are then combined into a demand on the eliminator used to match the whole list, with $\hole$ again used to represent the absence of demand on the nil branch. Records are similar, except that there is only a single branch. The selection state $\beta$ computed for the initial part of the record is an artefact of processing records recursively, and is disregarded.

\begin{lemma}[Monotonicity of $\matchBwdF{w}$]
   Suppose $w :: \raw{v}, \raw{\sigma} \matchR \raw{\rho}, \raw{\kappa}$, with $\rho, \kappa, \alpha \matchBwdR{w} v, \sigma$ and $\rho', \kappa', \alpha' \matchBwdR{w} v', \sigma'$. If $(\rho, \kappa, \alpha) \leq (\rho', \kappa', \alpha')$ then $(v, \sigma) \leq (v', \sigma)$.
\end{lemma}

\subsubsection{Backward evaluation}
\label{sec:data-dependencies:analyses:bwd:eval}

\figref{data-dependencies:bwd} defines a family of \emph{backward-evaluation} functions $\evalBwdF{T}$ of type $\Sel{\raw{v}}{A} \to (\Sel{\raw{\rho}, \raw{e}}{A}) \times \Ann{A}$ for any $T :: \raw{\rho}, \raw{e} \evalR \raw{v}$. Backward evaluation rewinds $T$, using the output selection $v \in \Sel{\raw{v}}{A}$ to determine an input selection $(\rho, e) \in \Sel{\raw{\rho}, \raw{e}}{A}$ and an argument demand $\alpha \in \Ann{A}$ which will eventually be pushed back onto the argument of the dynamically innermost function call. (At the outermost level, where there are no active function calls, the argument demand is discarded.) The rules resemble those of the evaluation relation $\evalR$ with inputs and outputs flipped. The general pattern is that each backward rule takes the join of the demand attached to any partial values constructed at that step, and the argument demand associated with any subcomputations, and passes it upwards as the new argument demand. The output environment is constructed similarly, by joining the demand flowing back through the environment copies used to evaluate subcomputations. Demand is also attached to the source expression when it is the expression form responsible for the construction of a demanded value.

\input{fig/core-language/slicing/eval-bwd}

\Paragraph{Function application} The application rule is where the argument demand is used and the function context changes, so we start here. The rule essentially runs the forward evaluation rule in reverse, using the trace $T'$ to backward-evaluate the function body. The argument demand $\beta$ associated with $T'$ is the join of the demand on any resources constructed directly by that function invocation, and is transferred to the matched part of the function argument by the backward-match function $\matchBwdF{w}$. The argument demand passed upwards into the enclosing function context is $\alpha \join \alpha'$, representing the resources needed along $T$ and $U$. The auxiliary function $\smash{\closeDefsBwdF{\rho, h}}: \smash{\Sel{\raw{\rho'}}{A} \to (\Sel{\raw{\rho}, \raw{h}}{A})} \times \Ann{A}$ for any $\raw{\rho}, \raw{h} \closeDefsR \raw{\rho'}$ defined at the bottom of \figref{data-dependencies:bwd} is used to turn $\rho_2$, capturing the demand flowing back through any recursive uses of the function and any others with which it was mutually defined, into information that can be merged back into the demand on the closure. The function $\closeDefsBwdF{\rho,h}$ is also used in the letrec rule, which otherwise follows the general pattern described above.

\Paragraph{Primitive application} Each primitive operation $\phi: \tyInt^{i} \to \tyInt$ must provide a backward-dependency  function $\primBwdBool{\phi}{\vec{n}}: \Ann{A} \to \Ann{A}^i$ for every $\vec{n} \in \tyInt^i$ which specifies how to turn the output selection $\alpha'$ on $\exAppPrim{\phi}{\vec{n}}$ into an input selection $\vec{a} \in \Ann{A}^i$ on $\vec{n}$. The rule for primitive application uses this information to pair each argument $n_i$ with its demand $\alpha_i$ and then backwards-evaluate the argument. The argument demand passed upward is the join of those arising from these subcomputations, and is unrelated to the execution of the primitive itself, similar to a function application. Here $\bigjoin{\vec{\beta}}$ means the fold of $\join$ (with unit $\bot$) over the sequence of selection states $\seqRange{\beta_1}{\beta_{\length{\vec{x}}}'}$. Environment demands $\vec{\rho} = \seqRange{\rho_1}{\rho_{\length{\vec{n}}}}$ are joined (pointwise) in a similar fashion.

\Paragraph{Other rules} In the variable case, no partial values were constructed during evaluation and there are no subcomputations, so the argument demand is $\bot$, the unit for $\join$. The returned environment selection demands $v$ for the variable $x$ and $\hole$ for all other variables, using the family of \emph{backwards lookup} functions $\envLookupBwdF{-}{\rho}{x}{-}$ of type $\Sel{\raw{v}}{A} \to \Sel{\raw{\rho}}{A}$ for any $\envLookup{\raw{\rho}}{x}{\raw{v}}$ also defined in \figref{data-dependencies:bwd}. (The output of the function is on the left in the relational notation.) For atomic values such as integers, Booleans and nil, the argument demand is simply the demand $\alpha$ associated with the constructed value, which is also attached to the corresponding expression, and the environment demand has $\hole$ for every variable in the original environment $\raw{\rho}$, written $\hole_{\raw{\rho}}$.

For closures, the argument demand is unpacked along with the other components, preserving any internal selections on $\rho$ and $\sigma$. Composite values such as records and cons cells follow the general pattern; thus for records, the argument demands $\alpha'_i$ from the subcomputations are joined with the $\alpha$ on the record itself to produce the argument demand passed upward. Record projection never demands the record constructor itself, but simply promotes the field demand into a record demand, using $\envLookupBwdR{\vec{\bind{x}{\raw{v}}}}$ to demand fields other than $y$ with $\hole$.

\Paragraph{Hole rule} The hole rule, as elsewhere, ensures that the function is defined when $v$ is $\hole$, and it is easy to show that $\evalBwdF{T}$  preserves $\leq$, and thus $\eq$.

\begin{lemma}[Monotonicity of $\evalBwdF{T}$]
   Suppose $T :: \raw{\rho}, \raw{e} \evalR \raw{v}$ with $v \evalBwdR{T} \rho, e, \alpha $ and $v' \evalBwdR{T} \rho', e', \alpha' $. If $v \leq v'$ then $(\rho, e, \alpha) \leq (\rho', e', \alpha')$.
\end{lemma}

\newpage
\subsection{Round-tripping properties of $\evalFwdF{T}$ and $\evalBwdF{T}$}
\label{sec:data-dependencies:galois-connections}

We now establish more formally the round-tripping properties, alluded at the beginning of the section, that relate $\evalFwdF{T}$ to $\evalBwdF{T}$. For the analyses to be coherent, we expect $\evalFwdF{T}(\evalBwdF{T}(v))$ to produce a value selection $v' \geq v$, and $\evalBwdF{T}(\evalFwdF{T}(\rho,e))$ to produce an input selection $(\rho',e') \leq (\rho,e)$. Pairs of (monotonic) functions $f: X \to Y$ and $g: Y \to X$ that are related in this way are called \emph{Galois connections}. Galois connections generalise isomorphisms: $f$ and $g$ are not quite mutual inverses, but are the nearest to an inverse each can get to the other. We will present a visual example of some of these round-tripping properties in \secref{de-morgan:example}; here we establish the relevant theorems.

\begin{definition}[Galois connection]
   Suppose $X$ and $Y$ are sets equipped with partial orders $\numleq_X$ and $\numleq_Y$. Then monotonic functions $f: X \to Y$ and $g: Y \to X$ form a \emph{Galois connection} $(f, g): X \to Y$ iff $g(f(x)) \numgeq_X x$ and $f(g(y)) \numleq_Y y$.
\end{definition}

\noindent Galois connections are also adjoint functors between poset categories, with left and right adjoints $f$ and $g$  usually called the \emph{lower} and \emph{upper} adjoints, because $f$ approximates an inverse of $g$ from below, and $g$ an inverse of $f$ from above. Galois connections compose component-wise, so it is useful to think of them as having a type $X \to Y$, with the direction (by convention) given by the lower adjoint. If $\gamma: X \to Y$ is a Galois connection, we will write $\lowerAdj{\gamma}$ and $\upperAdj{\gamma}$ for the lower and upper adjoints respectively; an important property we will return to is that $\lowerAdj{\gamma}$ preserves joins and $\upperAdj{\gamma}$ preserves meets. We now show that, for any $\Ann{A}$, $\evalBwdF{T}$ and $\evalFwdF{T}$ form a Galois connection (\thmref{core-language:eval:gc}), by first establishing that the relevant auxiliary functions also form Galois connections.

\begin{theorem}[Galois connection for pattern-matching]
   \label{thm:core-language:match:gc}
   Suppose $w :: \raw{v}, \raw{\sigma} \matchR \raw{\rho}, \raw{\kappa}$.  Then $(\matchBwdF{w}, \matchFwdF{w}): (\Sel{\raw{\rho},\raw{\kappa}}{A}) \times \Ann{A} \to \Sel{\raw{v}, \raw{\sigma}}{A}$ is a Galois connection.
\end{theorem}

\begin{proof}
\ifappendices See \appref{proofs:match:gc}. \else \ProofInSupplementaryMaterial \fi
\end{proof}

\begin{lemma}[Galois connection for environment lookup]
   \label{lem:core-language:env-get-put}
   Suppose $\envLookup{\raw{\rho}}{x}{\raw{v}}$. Then $(\envLookupBwdF{-}{\raw{\rho}}{x}{},\envLookupFwdF{}{\raw{\rho}}{x}{-}): \Sel{\raw{v}}{A} \to \Sel{\raw{\rho}}{A}$ is a Galois connection.
\end{lemma}

\begin{proof}
   \ifappendices See \appref{proofs:lookup:gc}. \else \ProofInSupplementaryMaterial \fi
   \end{proof}

   \begin{theorem}[Galois connection for recursive bindings]
\label{thm:core-language:closeDefs:gc}
   Suppose $\raw{\rho}, \raw{h} \closeDefsR \raw{\rho}'$. Then $({\closeDefsBwdF{\raw{\rho},\raw{h}}, \closeDefsFwdF{\raw{\rho}, \raw{h}}}): \Sel{\raw{\rho}'}{A} \to (\Sel{\raw{\rho},\raw{h}}{A}) \times \Ann{A}$ is a Galois connection.
\end{theorem}

\begin{proof}
   \ifappendices See \appref{proofs:closeDefs:gc}. \else \ProofInSupplementaryMaterial \fi
   \end{proof}

We assume (rather than prove) that the backward and forward dependency functions $\primBwdBool{\phi}{\vec{n}}$ and $\primFwdBool{\phi}{\vec{n}}$ provided for every primitive operation $\phi: \tyInt^i \to \tyInt$ and every $\vec{n}$ of length $i$ form a Galois connection of type $\Ann{A} \to \Ann{A}^i$. Under this assumption the following holds.

\begin{theorem}[Galois connection for evaluation]
\label{thm:core-language:eval:gc}
   Suppose $T :: \raw{\rho}, \raw{e} \evalR \raw{v}$.  Then $(\evalBwdF{T}, \evalFwdF{T}): \Sel{\raw{v}}{A} \to (\Sel{\raw{\rho}, \raw{e}}{A}) \times \Ann{A}$ is a Galois connection.
\end{theorem}

\begin{proof}
   \ifappendices See \appref{proofs:eval:gc}. \else \ProofInSupplementaryMaterial \fi
\end{proof}

Establishing that $(\evalBwdF{T}, \evalFwdF{T})$ is an adjoint pair might seem rather weak as a correctess property: it merely ensures that the two analyses are related in a sensible way, not that they actually capture any useful information. This is a familiar problem from other approximate analyses like type systems and model checking, where properties like soundness or completeness are essential but do not by themselves guarantee utility. One could certainly define versions of $\evalBwdF{T}$ and $\evalFwdF{T}$ that are too coarse grained to be useful, yet still satisfy \thmref{core-language:eval:gc}. However Galois connections do at least require that every tightening or tweak to the forward analysis is paired with a corresponding adjustment to the backward analysis, and vice-versa. In \secref{conclusion} we consider how other ideas from provenance and program slicing might be adapted to provide additional correctness criteria.
